{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbed3bdf",
   "metadata": {},
   "source": [
    "# Project Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818b7d04",
   "metadata": {},
   "source": [
    "## Install and import the required libraries\n",
    "\n",
    "<br>\n",
    "In the implementation part, we will start by importing the required libraries for our work. We will work mainly with yfinance for data collection, Pandas and Numpy for data processing, and TensorFlow for machine learning.\n",
    "\n",
    "<br>\n",
    "Other relevant libraries are keras_tuner for hyperparameter optimization, scikit-learn for data scaling and model evaluation, pandas-ta for calculating technical indicators based on the data from yfinance, and matplotlib for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5d434b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install Dependencies and import libraries\n",
    "# !pip install yfinance pandas numpy tensorflow scikit-learn pandas-ta matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a1838df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pypi.org/project/yfinance/ (\"\"\" it's an open-source tool that uses Yahoo's publicly available APIs, and is intended for research and educational purposes. \"\"\")\n",
    "# import yfinance, our data source\n",
    "import yfinance as yf\n",
    "\n",
    "# import pandas and numpy\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# import from tensorflow\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, LSTM, Input, GRU, SeparableConv1D, BatchNormalization, MaxPooling1D, add, Layer, concatenate\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.saving import register_keras_serializable\n",
    "\n",
    "# import from keras_tuner\n",
    "from keras_tuner import HyperModel, Hyperband, Tuner, Oracle\n",
    "\n",
    "# import from scikit-learn\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# https://pypi.org/project/pandas-ta/ (\"\"\"An easy to use Python 3 Pandas Extension with 130+ Technical Analysis Indicators. Can be called from a Pandas DataFrame or standalone\"\"\")\n",
    "# import pandas-ta\n",
    "import pandas_ta as ta\n",
    "\n",
    "# import matplotlib for data visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# this library allow us to calculate how long a process would take \n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4008eb22",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "\n",
    "<br>\n",
    "In this implementation, we will work with 5 different stocks from the S&P500(1) list. The 5 stocks we will work with are chosen based on their ranking in this list from most valuable to least valuable, and each one is relatively distant from the other and belongs to a different industry. This will ensure a diverse sample and that our model evaluation results generalize relatively well, reducing the possibility of bias and overfitting.\n",
    "\n",
    "Check out our stock list for this project (2).\n",
    "\n",
    "<br>\n",
    "The yfinance API allows us to request the stock data for a company's given period and interval values. For the period value, we will set it to 10 years or max value which will be sufficient for all of our experiments, for the interval value however, which determines the frequency of the data rows, we will experiment with many options to see if our approach generalizes better with specific interval values as different intervals are relevant to other groups of financial analysts and traders in the real world, therefore we must try to create the best model relevant to each of these groups.\n",
    "\n",
    "That's why we will define a function that allows us to download any number of stock data at any period or interval, save the data as a CSV file to local storage, load it from storage, split it into different data frames based on the stock, and organize the data frames in a dictionary so it's easy to work with for the rest of the project.\n",
    "\n",
    "Check out the loadData function (3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2cc26a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert the stock symbols into a list\n",
    "symbols_list = ['PFE', 'ROP', 'XYL', 'CPAY', 'INCY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23d381e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to load the data from source (yfinance API), and save it as a csv to local storage\n",
    "def loadData(symbols=symbols_list, period='10y', interval='1wk'):\n",
    "    \n",
    "    try:\n",
    "        # load the the dataframe from the csv file if it already exist\n",
    "        df = pd.read_csv(f'{period}_{interval}_stocks_data.csv').set_index(['Date', 'Ticker'])\n",
    "        \n",
    "        print(\"Data loaded from directory\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        # print a message stating the data does not already exists and need to be downloaded from yfinance\n",
    "        print(f\"There is no {period}_{interval}_stocks_data.csv. Data will be downloaded from yfinance.\")\n",
    "        \n",
    "        # download the data from source and store it in the stock_data variable which will hold the data as a pandas dataframe\n",
    "        stocks_data =  yf.download(symbols, period=period, interval=interval)\n",
    "\n",
    "        # reshape the dataframe as a multi-level index dataframe\n",
    "        stocks_data = stocks_data.stack()\n",
    "\n",
    "        # source: https://www.statology.org/pandas-change-column-names-to-lowercase/\n",
    "        # convert column names to lowercase\n",
    "        stocks_data.columns = stocks_data.columns.str.lower()\n",
    "\n",
    "        # save the dataframe to a csv file (Save the data to a CSV so we don't have to make any extra unnecessary requests to the API every time we reload the notebook)\n",
    "        stocks_data.to_csv(f'{period}_{interval}_stocks_data.csv', index=True)\n",
    "\n",
    "        # load the the dataframe from the csv file\n",
    "        df = pd.read_csv(f'{period}_{interval}_stocks_data.csv').set_index(['Date', 'Ticker'])\n",
    "\n",
    "    finally: \n",
    "        # create a dict to store the dataframe of each unique symbol where keys are symbol, values are dataframes\n",
    "        df_dict = {}\n",
    "\n",
    "        # iterate over the symbols\n",
    "        for symbol in symbols:\n",
    "\n",
    "            # source of inspiration https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.xs.html [11]\n",
    "            # extract the specific stock data at the 'Ticker' level of this multi index dataframe and save it as a dataframe\n",
    "            symbol_df = df.xs(symbol, axis=0, level='Ticker', drop_level=True)\n",
    "\n",
    "            # store the datafram into the df_dict\n",
    "            df_dict[symbol] = symbol_df\n",
    "\n",
    "        # return the dictionary\n",
    "        return df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb106efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no 10y_1wk_stocks_data.csv. Data will be downloaded from yfinance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  5 of 5 completed\n"
     ]
    }
   ],
   "source": [
    "# load the stock data for the 5 companies into a dictionary\n",
    "dfs = loadData(symbols=symbols_list, period='10y', interval='1wk')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf797fe",
   "metadata": {},
   "source": [
    "## Perform simple exploritory data analysis\n",
    "\n",
    "<br> \n",
    "Now that we have a dictionary of dataframes, we can analyze the data and make some observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92f5532",
   "metadata": {},
   "source": [
    "1. We can get the shape of the data for any stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "131bb889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol: PFE, Shape: (523, 6) \n",
      "Symbol: ROP, Shape: (523, 6) \n",
      "Symbol: XYL, Shape: (523, 6) \n",
      "Symbol: CPAY, Shape: (523, 6) \n",
      "Symbol: INCY, Shape: (523, 6) \n"
     ]
    }
   ],
   "source": [
    "# the data shape\n",
    "for symbol in dfs.keys():\n",
    "    print(f\"Symbol: {symbol}, Shape: {dfs[symbol].shape} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9819a69a",
   "metadata": {},
   "source": [
    "2. We can get the basic stats for any stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58a995d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adj close</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>523.000000</td>\n",
       "      <td>523.000000</td>\n",
       "      <td>523.000000</td>\n",
       "      <td>523.000000</td>\n",
       "      <td>523.000000</td>\n",
       "      <td>5.230000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.870774</td>\n",
       "      <td>36.269160</td>\n",
       "      <td>37.066481</td>\n",
       "      <td>35.423588</td>\n",
       "      <td>36.250718</td>\n",
       "      <td>1.373323e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.594988</td>\n",
       "      <td>6.862873</td>\n",
       "      <td>7.114429</td>\n",
       "      <td>6.536369</td>\n",
       "      <td>6.851178</td>\n",
       "      <td>6.265050e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.923565</td>\n",
       "      <td>25.400000</td>\n",
       "      <td>26.170000</td>\n",
       "      <td>25.200001</td>\n",
       "      <td>25.580000</td>\n",
       "      <td>3.922725e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.773307</td>\n",
       "      <td>31.555978</td>\n",
       "      <td>32.129982</td>\n",
       "      <td>30.858634</td>\n",
       "      <td>31.555977</td>\n",
       "      <td>9.714320e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.344492</td>\n",
       "      <td>34.478176</td>\n",
       "      <td>34.914612</td>\n",
       "      <td>33.785580</td>\n",
       "      <td>34.487667</td>\n",
       "      <td>1.215046e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>33.093800</td>\n",
       "      <td>40.028976</td>\n",
       "      <td>40.682581</td>\n",
       "      <td>39.165085</td>\n",
       "      <td>40.033976</td>\n",
       "      <td>1.583856e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>52.740730</td>\n",
       "      <td>59.480000</td>\n",
       "      <td>61.709999</td>\n",
       "      <td>57.160000</td>\n",
       "      <td>60.599998</td>\n",
       "      <td>6.333997e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        adj close       close        high         low        open  \\\n",
       "count  523.000000  523.000000  523.000000  523.000000  523.000000   \n",
       "mean    29.870774   36.269160   37.066481   35.423588   36.250718   \n",
       "std      7.594988    6.862873    7.114429    6.536369    6.851178   \n",
       "min     17.923565   25.400000   26.170000   25.200001   25.580000   \n",
       "25%     23.773307   31.555978   32.129982   30.858634   31.555977   \n",
       "50%     28.344492   34.478176   34.914612   33.785580   34.487667   \n",
       "75%     33.093800   40.028976   40.682581   39.165085   40.033976   \n",
       "max     52.740730   59.480000   61.709999   57.160000   60.599998   \n",
       "\n",
       "             volume  \n",
       "count  5.230000e+02  \n",
       "mean   1.373323e+08  \n",
       "std    6.265050e+07  \n",
       "min    3.922725e+07  \n",
       "25%    9.714320e+07  \n",
       "50%    1.215046e+08  \n",
       "75%    1.583856e+08  \n",
       "max    6.333997e+08  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data basic stats\n",
    "dfs[\"PFE\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61939595",
   "metadata": {},
   "source": [
    "3. We can check how many missing values each column have for a any stock dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7a2bbde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adj close    0\n",
       "close        0\n",
       "high         0\n",
       "low          0\n",
       "open         0\n",
       "volume       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many null values in each column\n",
    "dfs['PFE'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988fc639",
   "metadata": {},
   "source": [
    "## Add Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34780aca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
