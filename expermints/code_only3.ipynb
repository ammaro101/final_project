{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "22168f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Project prototype (implementation)\n",
    "## Install Dependencies and import libraries\n",
    "\n",
    "# pip install pandas numpy yfinance pandas-ta scikit-learn tensorflow\n",
    "\n",
    "# https://pypi.org/project/yfinance/ (\"\"\" it's an open-source tool that uses Yahoo's publicly available APIs, and is intended for research and educational purposes. \"\"\")\n",
    "# import yfinance, our data source\n",
    "import yfinance as yf\n",
    "\n",
    "# https://pypi.org/project/pandas-ta/ (\"\"\"An easy to use Python 3 Pandas Extension with 130+ Technical Analysis Indicators. Can be called from a Pandas DataFrame or standalone\"\"\")\n",
    "# import pandas-ta\n",
    "import pandas_ta as ta\n",
    "\n",
    "# import pandas and numpy\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# import matplotlib for data visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import from scikit-learn\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# import from tensorflow\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, LSTM, Input, GRU, SeparableConv1D, BatchNormalization, Conv1D, MaxPooling1D, add, Layer, concatenate, Flatten\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from keras_tuner import HyperModel, Hyperband, Tuner, Oracle\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984fbc43",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cf16548c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no max_1wk_stocks_data.csv. Data will be downloaded from yfinance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  5 of 5 completed\n"
     ]
    }
   ],
   "source": [
    "# insert the stock symbols into a list\n",
    "symbols_list = ['PFE', 'ROP', 'XYL', 'CPAY', 'INCY']\n",
    "\n",
    "# define a function to load the data from source (yfinance API), and save it as a csv to local storage\n",
    "def loadData(symbols=symbols_list, period='max', interval='1wk'):\n",
    "    \n",
    "    try:\n",
    "        # load the the dataframe from the csv file if it already exist\n",
    "        df = pd.read_csv(f'{period}_{interval}_stocks_data.csv').set_index(['Date', 'Ticker'])\n",
    "        \n",
    "        print(\"Data loaded from directory\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        # print a message stating the data does not already exists and need to be downloaded from yfinance\n",
    "        print(f\"There is no {period}_{interval}_stocks_data.csv. Data will be downloaded from yfinance.\")\n",
    "        \n",
    "        # download the data from source and store it in the stock_data variable which will hold the data as a pandas dataframe\n",
    "        stocks_data =  yf.download(symbols, period=period, interval=interval)\n",
    "\n",
    "        # reshape the dataframe as a multi-level index dataframe\n",
    "        stocks_data = stocks_data.stack()\n",
    "\n",
    "        # source: https://www.statology.org/pandas-change-column-names-to-lowercase/\n",
    "        # convert column names to lowercase\n",
    "        stocks_data.columns = stocks_data.columns.str.lower()\n",
    "\n",
    "        # save the dataframe to a csv file (Save the data to a CSV so we don't have to make any extra unnecessary requests to the API every time we reload the notebook)\n",
    "        stocks_data.to_csv(f'{period}_{interval}_stocks_data.csv', index=True)\n",
    "\n",
    "        # load the the dataframe from the csv file\n",
    "        df = pd.read_csv(f'{period}_{interval}_stocks_data.csv').set_index(['Date', 'Ticker'])\n",
    "\n",
    "    finally: \n",
    "        # create a dict to store the dataframe of each unique symbol where keys are symbol, values are dataframes\n",
    "        df_dict = {}\n",
    "\n",
    "        # iterate over the symbols\n",
    "        for symbol in symbols:\n",
    "\n",
    "            # source of inspiration https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.xs.html [11]\n",
    "            # extract the specific stock data at the 'Ticker' level of this multi index dataframe and save it as a dataframe\n",
    "            symbol_df = df.xs(symbol, axis=0, level='Ticker', drop_level=True)\n",
    "\n",
    "            # store the datafram into the df_dict\n",
    "            df_dict[symbol] = symbol_df\n",
    "\n",
    "        # return the dictionary\n",
    "        return df_dict\n",
    "\n",
    "\n",
    "dfs = loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "910aa98b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adj close</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1972-05-29</th>\n",
       "      <td>0.159691</td>\n",
       "      <td>0.805463</td>\n",
       "      <td>0.817817</td>\n",
       "      <td>0.802993</td>\n",
       "      <td>0.815346</td>\n",
       "      <td>4072656.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972-06-05</th>\n",
       "      <td>0.162630</td>\n",
       "      <td>0.820288</td>\n",
       "      <td>0.825229</td>\n",
       "      <td>0.798051</td>\n",
       "      <td>0.805463</td>\n",
       "      <td>8595581.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972-06-12</th>\n",
       "      <td>0.165569</td>\n",
       "      <td>0.835112</td>\n",
       "      <td>0.837583</td>\n",
       "      <td>0.810405</td>\n",
       "      <td>0.820288</td>\n",
       "      <td>11312372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972-06-19</th>\n",
       "      <td>0.166549</td>\n",
       "      <td>0.840054</td>\n",
       "      <td>0.854878</td>\n",
       "      <td>0.820288</td>\n",
       "      <td>0.835112</td>\n",
       "      <td>9986861.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972-06-26</th>\n",
       "      <td>0.166059</td>\n",
       "      <td>0.837583</td>\n",
       "      <td>0.849937</td>\n",
       "      <td>0.817817</td>\n",
       "      <td>0.840054</td>\n",
       "      <td>9025613.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-15</th>\n",
       "      <td>29.552921</td>\n",
       "      <td>29.969999</td>\n",
       "      <td>30.690001</td>\n",
       "      <td>28.830000</td>\n",
       "      <td>29.030001</td>\n",
       "      <td>180142400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-22</th>\n",
       "      <td>30.341789</td>\n",
       "      <td>30.770000</td>\n",
       "      <td>30.930000</td>\n",
       "      <td>29.309999</td>\n",
       "      <td>30.110001</td>\n",
       "      <td>179544200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-29</th>\n",
       "      <td>30.430000</td>\n",
       "      <td>30.430000</td>\n",
       "      <td>31.540001</td>\n",
       "      <td>29.780001</td>\n",
       "      <td>30.690001</td>\n",
       "      <td>254667700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-05</th>\n",
       "      <td>28.549999</td>\n",
       "      <td>28.549999</td>\n",
       "      <td>30.049999</td>\n",
       "      <td>28.450001</td>\n",
       "      <td>29.090000</td>\n",
       "      <td>157625900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-12</th>\n",
       "      <td>28.299999</td>\n",
       "      <td>28.299999</td>\n",
       "      <td>29.180000</td>\n",
       "      <td>27.850000</td>\n",
       "      <td>28.580000</td>\n",
       "      <td>207095624.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2725 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            adj close      close       high        low       open       volume\n",
       "Date                                                                          \n",
       "1972-05-29   0.159691   0.805463   0.817817   0.802993   0.815346    4072656.0\n",
       "1972-06-05   0.162630   0.820288   0.825229   0.798051   0.805463    8595581.0\n",
       "1972-06-12   0.165569   0.835112   0.837583   0.810405   0.820288   11312372.0\n",
       "1972-06-19   0.166549   0.840054   0.854878   0.820288   0.835112    9986861.0\n",
       "1972-06-26   0.166059   0.837583   0.849937   0.817817   0.840054    9025613.0\n",
       "...               ...        ...        ...        ...        ...          ...\n",
       "2024-07-15  29.552921  29.969999  30.690001  28.830000  29.030001  180142400.0\n",
       "2024-07-22  30.341789  30.770000  30.930000  29.309999  30.110001  179544200.0\n",
       "2024-07-29  30.430000  30.430000  31.540001  29.780001  30.690001  254667700.0\n",
       "2024-08-05  28.549999  28.549999  30.049999  28.450001  29.090000  157625900.0\n",
       "2024-08-12  28.299999  28.299999  29.180000  27.850000  28.580000  207095624.0\n",
       "\n",
       "[2725 rows x 6 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[symbols_list[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08027413",
   "metadata": {},
   "source": [
    "# Add Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0a5a8d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that takes a dataframe and create 'next_close' column based on its 'close' column\n",
    "def get_next_close(_df):\n",
    "    \n",
    "    # create the 'next_close' column to be equal to the next closing price\n",
    "    # this can be accomplished easily by shifting the close column backward by 1\n",
    "    return _df['close'].shift(-1)\n",
    "\n",
    "# create a function that returns 1 if the the next closing price is higher than current closing price and 0 otherwise.\n",
    "def assign_trend(row):\n",
    "    if row['next_close'] > row['close']:\n",
    "        return 1\n",
    "    elif row['next_close'] < row['close']:\n",
    "        return 0\n",
    "    else: # if the next value is missing then return NaN\n",
    "        return np.nan\n",
    "\n",
    "# create a function that add the target columns to the dataframe\n",
    "def add_targets(_df):\n",
    "    \n",
    "    # add the next_close column to the dataframe\n",
    "    _df['next_close'] = get_next_close(_df)\n",
    "    \n",
    "    # add the trend column to the dataframe\n",
    "    _df['trend'] = _df.apply(assign_trend, axis=1)\n",
    "    \n",
    "    # drop the NaN values\n",
    "    _df.dropna(inplace=True)\n",
    "    \n",
    "    # fix the 'trend' data type to be int\n",
    "    _df = _df.astype({'trend': int})\n",
    "    \n",
    "    return _df\n",
    "\n",
    "# add target columns to all the data frames\n",
    "# df = add_targets(dfs[symbols_list[0]])\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d6eb2d",
   "metadata": {},
   "source": [
    "# Features Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac283a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  we can easily check the available indicators in the pandas-ta library\n",
    "# help(df.ta.indicators())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9401d84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(ta.donchian)\n",
    "# df.ta.donchian()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f70aa6f",
   "metadata": {},
   "source": [
    "65 different technical indicators columns were added in this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "da6d64f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the time being let's create a function that add all the technical indicators we want to a df\n",
    "def add_technical_indicators(_df):\n",
    "    # apply macd on the close column in a df and add it to the dataframe    \n",
    "    macd = ta.macd(_df['close'])\n",
    "    # The MACD (Moving Average Convergence/Divergence) is a popular indicator to that is used to identify a trend\n",
    "    _df.insert(6, 'macd', macd.iloc[:,0])\n",
    "    # Histogram is the difference of MACD and Signal\n",
    "    _df.insert(7, 'macd_histogram', macd.iloc[:,1])\n",
    "    # Signal is an EMA (exponential moving average) of MACD\n",
    "    _df.insert(8, 'macd_signal', macd.iloc[:,2])\n",
    "    \n",
    "    # apply RSI on the Close column in a df and add it to the dataframe    \n",
    "    # RSI (Relative Strength Index) is popular momentum oscillator. Measures velocity and magnitude a trend\n",
    "    rsi = ta.rsi(_df['close'])\n",
    "    _df.insert(9, 'rsi', rsi)\n",
    "\n",
    "    # apply SMA on the Close column in a df and add it to the dataframe    \n",
    "    # SMA (Simple Moving Average) is the classic moving average that is the equally weighted average over n periods.\n",
    "    sma = ta.sma(_df['close'])\n",
    "    _df.insert(10, 'sma', sma)\n",
    "\n",
    "    # apply EMA on the Close column in a df and add it to the dataframe    \n",
    "    # EMA (Exponential Moving Average). The weights are determined by alpha which is proportional to it's length.\n",
    "    ema = ta.ema(_df['close'])\n",
    "    _df.insert(11, 'ema', ema)\n",
    "\n",
    "    ######## repeat the same proccess for all the technical indicators we want to include ##########\n",
    "    # aberration: A volatility indicator\n",
    "    aberration = ta.aberration(_df['high'], _df['low'], _df['close'])\n",
    "    _df.insert(12, 'aberration_zg', aberration.iloc[:,0])\n",
    "    _df.insert(13, 'aberration_sg', aberration.iloc[:,1])\n",
    "    _df.insert(14, 'aberration_xg', aberration.iloc[:,2])\n",
    "    _df.insert(15, 'aberration_atr', aberration.iloc[:,3])\n",
    "    \n",
    "    # bbands: A popular volatility indicator by John Bollinger.\n",
    "    bbands = ta.bbands(_df['close'])\n",
    "    _df.insert(16, 'bbands_lower', bbands.iloc[:,0])\n",
    "    _df.insert(17, 'bbands_mid', bbands.iloc[:,1])\n",
    "    _df.insert(18, 'bbands_upper', bbands.iloc[:,2])\n",
    "    _df.insert(19, 'bbands_bandwidth', bbands.iloc[:,3])\n",
    "    _df.insert(20, 'bbands_percent', bbands.iloc[:,4])\n",
    "    \n",
    "    # adx:  Average Directional Movement is meant to quantify trend strength by measuring the amount of movement in a single direction.    \n",
    "    adx = ta.adx(_df['high'], _df['low'], _df['close'])\n",
    "    _df.insert(21, 'adx_adx', adx.iloc[:,0])\n",
    "    _df.insert(22, 'adx_dmp', adx.iloc[:,1])\n",
    "    _df.insert(23, 'adx_dmn', adx.iloc[:,2])\n",
    "\n",
    "    # atr: Averge True Range is used to measure volatility, especially volatility caused by gaps or limit moves.\n",
    "    atr = ta.atr(_df['high'], _df['low'], _df['close'])\n",
    "    _df.insert(24, 'atr', atr)\n",
    "    \n",
    "    # stoch: The Stochastic Oscillator (STOCH) was developed by George Lane in the 1950's. He believed this indicator was a good way to measure momentum because changes in momentum precede changes in price.\n",
    "    stoch = ta.stoch(_df['high'], _df['low'], _df['close'])\n",
    "    _df.insert(25, 'stoch_k', stoch.iloc[:,0])\n",
    "    _df.insert(26, 'stoch_d', stoch.iloc[:,1])\n",
    "    \n",
    "    # obv: On Balance Volume is a cumulative indicator to measure buying and selling pressure.\n",
    "    obv = ta.obv(_df['close'], _df['volume'])\n",
    "    _df.insert(27, 'obv', obv)\n",
    "    \n",
    "    # Supertrend: is an overlap indicator. It is used to help identify trend direction, setting stop loss, identify support and resistance, and/or generate buy & sell signals.\n",
    "    supertrend = ta.supertrend(_df['high'], _df['low'], _df['close'])\n",
    "    _df.insert(28, 'supertrend_trend', supertrend.iloc[:,0])\n",
    "    _df.insert(29, 'supertrend_direction', supertrend.iloc[:,1])\n",
    "    \n",
    "    # dema: The Double Exponential Moving Average attempts to a smoother average with less lag than the normal Exponential Moving Average (EMA).\n",
    "    dema = ta.dema(_df['close'])\n",
    "    _df.insert(30, 'dema', dema)\n",
    "    \n",
    "    # tema: A less laggy Exponential Moving Average.\n",
    "    tema = ta.tema(_df['close'])\n",
    "    _df.insert(31, 'tema', tema)\n",
    "\n",
    "    # roc: Rate of Change is an indicator is also referred to as Momentum. It is a pure momentum oscillator that measures the percent change in price with the previous price 'n' (or length) periods ago.\n",
    "    roc = ta.roc(_df['close'])\n",
    "    _df.insert(32, 'roc', roc)\n",
    "    \n",
    "    # mom: Momentum is an indicator used to measure a security's speed (or strength) of movement.  Or simply the change in price.\n",
    "    mom = ta.mom(_df['close'])\n",
    "    _df.insert(33, 'mom', mom)\n",
    "    \n",
    "    # cci: Commodity Channel Index is a momentum oscillator used to primarily identify overbought and oversold levels relative to a mean.\n",
    "    cci = ta.cci(_df['high'], _df['low'], _df['close'])\n",
    "    _df.insert(34, 'cci', cci)\n",
    "    \n",
    "    # aroon: attempts to identify if a security is trending and how strong.\n",
    "    aroon = ta.aroon(_df['high'], _df['low'])\n",
    "    _df.insert(35, 'aroon_up', aroon.iloc[:,0])\n",
    "    _df.insert(36, 'aroon_down', aroon.iloc[:,1])\n",
    "    _df.insert(37, 'aroon_osc', aroon.iloc[:,2])\n",
    "    \n",
    "    # natr: Normalized Average True Range attempt to normalize the average true range.\n",
    "    natr = ta.natr(_df['high'], _df['low'], _df['close'])\n",
    "    _df.insert(38, 'natr', natr)\n",
    "    \n",
    "    # William's Percent R is a momentum oscillator similar to the RSI that attempts to identify overbought and oversold conditions.\n",
    "    willr = ta.willr(_df['high'], _df['low'], _df['close'])\n",
    "    _df.insert(39, 'willr', willr)\n",
    "    \n",
    "    # vortex: Two oscillators that capture positive and negative trend movement.\n",
    "    vortex = ta.vortex(_df['high'], _df['low'], _df['close'])\n",
    "    _df.insert(40, 'vortex_vip', vortex.iloc[:,0])\n",
    "    _df.insert(41, 'vortex_vim', vortex.iloc[:,1])\n",
    "        \n",
    "    # kama: Developed by Perry Kaufman, Kaufman's Adaptive Moving Average (KAMA) is a moving average designed to account for market noise or volatility. KAMA will closely follow prices when the price swings are relatively small and the noise is low. KAMA will adjust when the price swings widen and follow prices from a greater distance. This trend-following indicator can be used to identify the overall trend, time turning points and filter price movements.\n",
    "    kama = ta.kama(_df['close'])\n",
    "    _df.insert(42, 'kama', kama)\n",
    "                       \n",
    "    # trix: is a momentum oscillator to identify divergences.\n",
    "    trix = ta.trix(_df['close'])\n",
    "    _df.insert(43, 'trix', trix.iloc[:,0])\n",
    "    _df.insert(44, 'trixs', trix.iloc[:,1])\n",
    "                       \n",
    "    # hlc3: the average of high, low, and close prices\n",
    "    hlc3 = ta.hlc3(_df['high'], _df['low'], _df['close'])\n",
    "    _df.insert(45, 'hlc3', hlc3)\n",
    "\n",
    "    # ohlc4: the average of open, high, low, and close prices\n",
    "    ohlc4 = ta.ohlc4(_df['open'], _df['high'], _df['low'], _df['close'])\n",
    "    _df.insert(46, 'ohlc4', ohlc4)\n",
    "    \n",
    "    # hma: The Hull Exponential Moving Average attempts to reduce or remove lag in moving averages.\n",
    "    hma = ta.hma(_df['close'])\n",
    "    _df.insert(47, 'hma', hma)\n",
    "\n",
    "    # vwma: Volume Weighted Moving Average.\n",
    "    vwma = ta.vwma(_df['close'], _df['volume'])\n",
    "    _df.insert(48, 'vwma', vwma)\n",
    "    \n",
    "    # accbands: Acceleration Bands created by Price Headley plots upper and lower envelope bands around a simple moving average.\n",
    "    accbands = ta.accbands(_df['high'], _df['low'], _df['close'])\n",
    "    _df.insert(49, 'accbands_lower', accbands.iloc[:,0])\n",
    "    _df.insert(50, 'accbands_mid', accbands.iloc[:,1])\n",
    "    _df.insert(51, 'accbands_upper', accbands.iloc[:,2])\n",
    "    \n",
    "    # adosc: Accumulation/Distribution Oscillator indicator utilizes Accumulation/Distribution and treats it similarily to MACD or APO.\n",
    "    adosc = ta.adosc(_df['high'], _df['low'], _df['close'], _df['volume'])\n",
    "    _df.insert(52, 'adosc', adosc)\n",
    "    \n",
    "    # alma: The ALMA moving average uses the curve of the Normal (Gauss) distribution, which can be shifted from 0 to 1. This allows regulating the smoothness and high sensitivity of the indicator. Sigma is another parameter that is responsible for the shape of the curve coefficients. This moving average reduces lag of the data in conjunction with smoothing to reduce noise.\n",
    "    alma = ta.alma(_df['close'])\n",
    "    _df.insert(53, 'alma', alma)\n",
    "    \n",
    "    # apo: The Absolute Price Oscillator is an indicator used to measure a security's momentum.  It is simply the difference of two Exponential Moving Averages (EMA) of two different periods. Note: APO and MACD lines are equivalent.\n",
    "    apo = ta.apo(_df['close'])\n",
    "    _df.insert(54, 'apo', apo)\n",
    "    \n",
    "    # cfo: The Forecast Oscillator calculates the percentage difference between the actualprice and the Time Series Forecast (the endpoint of a linear regression line).\n",
    "    cfo = ta.cfo(_df['close'])\n",
    "    _df.insert(55, 'cfo', cfo)\n",
    "    \n",
    "    # cg: The Center of Gravity Indicator by John Ehlers attempts to identify turning points while exhibiting zero lag and smoothing.\n",
    "    cg = ta.cg(_df['close'])\n",
    "    _df.insert(56, 'cg', cg)    \n",
    "    \n",
    "    # chop: The Choppiness Index was created by Australian commodity trader E.W. Dreiss and is designed to determine if the market is choppy (trading sideways) or not choppy (trading within a trend in either direction). Values closer to 100 implies the underlying is choppier whereas values closer to 0 implies the underlying is trending.\n",
    "    chop = ta.chop(_df['high'], _df['low'], _df['close'])\n",
    "    _df.insert(57, 'chop', chop)\n",
    "    \n",
    "    # cmf: Chailin Money Flow measures the amount of money flow volume over a specific period in conjunction with Accumulation/Distribution.\n",
    "    cmf = ta.cmf(_df['high'], _df['low'], _df['close'], _df['volume'])\n",
    "    _df.insert(58, 'cmf', cmf)\n",
    "    \n",
    "    # cmo: Attempts to capture the momentum of an asset with overbought at 50 and oversold at -50.\n",
    "    cmo = ta.cmo(_df['close'])\n",
    "    _df.insert(59, 'cmo', cmo)\n",
    "    \n",
    "    # coppock: Coppock Curve (originally called the \"Trendex Model\") is a momentum indicator is designed for use on a monthly time scale.  Although designed for monthly use, a daily calculation over the same period can be made, converting the periods to 294-day and 231-day rate of changes, and a 210-day weighted moving average.\n",
    "    coppock = ta.coppock(_df['close'])\n",
    "    _df.insert(60, 'coppock', coppock)\n",
    "    \n",
    "    # cti: The Correlation Trend Indicator is an oscillator created by John Ehler in 2020. It assigns a value depending on how close prices in that range are to following a positively- or negatively-sloping straight line. Values range from -1 to 1. This is a wrapper for ta.linreg(close, r=True).\n",
    "    cti = ta.cti(_df['close'])\n",
    "    _df.insert(61, 'cti', cti)\n",
    "    \n",
    "    # decay: Creates a decay moving forward from prior signals like crosses. The default is \"linear\". Exponential is optional as \"exponential\" or \"exp\".\n",
    "    decay = ta.decay(_df['close'])\n",
    "    _df.insert(62, 'decay', decay)\n",
    "    \n",
    "    # decreasing: Returns True if the series is decreasing over a period, False otherwise. If the kwarg 'strict' is True, it returns True if it is continuously decreasing over the period. When using the kwarg 'asint', then it returns 1 for True or 0 for False.\n",
    "    decreasing = ta.decreasing(_df['close'])\n",
    "    _df.insert(63, 'decreasing', decreasing)\n",
    "    \n",
    "    # dm: The Directional Movement was developed by J. Welles Wilder in 1978 attempts to determine which direction the price of an asset is moving. It compares prior highs and lows to yield to two series +DM and -DM.\n",
    "    dm = ta.dm(_df['high'], _df['low'])\n",
    "    _df.insert(64, 'dm_positive', dm.iloc[:,0])\n",
    "    _df.insert(65, 'dm_negative', dm.iloc[:,1])\n",
    "\n",
    "    # donchian: Donchian Channels are used to measure volatility, similar to Bollinger Bands and Keltner Channels.\n",
    "    donchian = ta.donchian(_df['high'], _df['low'])\n",
    "    _df.insert(66, 'donchian_lower', donchian.iloc[:,0])\n",
    "    _df.insert(67, 'donchian_mid', donchian.iloc[:,1])\n",
    "    _df.insert(68, 'donchian_upper', donchian.iloc[:,2])\n",
    "    \n",
    "    # ebsw: This indicator measures market cycles and uses a low pass filter to remove noise. Its output is bound signal between -1 and 1 and the maximum length of a detected trend is limited by its length input.\n",
    "    ebsw = ta.ebsw(_df['close'])\n",
    "    _df.insert(69, 'ebsw', ebsw)\n",
    "    \n",
    "    # efi: Elder's Force Index measures the power behind a price movement using price and volume as well as potential reversals and price corrections.\n",
    "    efi = ta.efi(_df['close'], _df['volume'])\n",
    "    _df.insert(70, 'efi', efi)\n",
    "    \n",
    "    # entropy: Introduced by Claude Shannon in 1948, entropy measures the unpredictability of the data, or equivalently, of its average information. A die has higher entropy (p=1/6) versus a coin (p=1/2).\n",
    "    entropy = ta.entropy(_df['close'])\n",
    "    _df.insert(71, 'entropy', entropy)\n",
    "\n",
    "    #### we can add more technical indicators if we want using the same process ####\n",
    "    \n",
    "    # remove the NaN values and return the new dataframe\n",
    "    _df.dropna(inplace=True)\n",
    "    \n",
    "    return _df\n",
    "\n",
    "# call the function on the selected dataframe\n",
    "# full_df = add_technical_indicators(df.copy(deep=True))\n",
    "# full_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea32a55",
   "metadata": {},
   "source": [
    "# Prepare the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8c599f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a deep copy of the data\n",
    "# full_df = add_technical_indicators(df.copy(deep=True))\n",
    "\n",
    "\n",
    "# create a function to apply a given scaler to the features\n",
    "def apply_scaler(scaler, features):\n",
    "    \n",
    "    # set the training and test ratio to be 70-30\n",
    "    training_ratio = int(len(features) * 0.7)\n",
    "\n",
    "    # devide the feature set into training and test set\n",
    "    X_train, X_test = features[:training_ratio], features[training_ratio:]\n",
    "    \n",
    "    # apply a scaler on the training and test sets in isolation so we don't allow the test set to influence the scaling process, which reduces the likelihood of overfitting \n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # concat the two scaled sets into one\n",
    "    X = np.concatenate((X_train_scaled, X_test_scaled), axis=0)\n",
    "\n",
    "    # return the scaled features\n",
    "    return X\n",
    "\n",
    "# source of isnpiration: https://stackoverflow.com/questions/47945512/how-to-reshape-input-for-keras-lstm?rq=4 [13]\n",
    "# create a function to reshape X and y into sequences of x timesteps\n",
    "def create_seqs(features, target, num_rows):\n",
    "    # create 2 empty lists to store the newly shaped features and target lists\n",
    "    X, y = [], []\n",
    "    \n",
    "    # iterate over the features\n",
    "    for i in range(len(features) - num_rows):\n",
    "        # create indexes of the start and end of each sequence\n",
    "        seq_s = i\n",
    "        seq_e = i + num_rows\n",
    "        \n",
    "        # the ith sequence will be a slice of the features between the indexes, create it and add it to X\n",
    "        xi = features[seq_s : seq_e]\n",
    "        X.append(xi)\n",
    "        \n",
    "        # do the same for the target and add it to y\n",
    "        yi = target[seq_e]\n",
    "        y.append(yi)\n",
    "    \n",
    "    # return the X and y as numpy arraies\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "# create a function to convert a dataframe into training and test sets\n",
    "def create_train_test_sets(_df, scaler, target=\"classification\", timesteps=6):\n",
    "\n",
    "    # reset the index\n",
    "    _df.reset_index(inplace = True)\n",
    "    \n",
    "    # drop the Date column as it's not necessary for now\n",
    "    _df.drop(['Date'], axis=1, inplace=True)\n",
    "\n",
    "    # set the features set\n",
    "    X = _df.iloc[:, :-2]\n",
    "    \n",
    "    # set the target \n",
    "    if (target == \"classification\"):\n",
    "        # trend is the target for classification\n",
    "        y = _df.iloc[:, -1]\n",
    "    else:\n",
    "        # next_close is the target for regression\n",
    "        y = _df.iloc[:, -2]\n",
    "\n",
    "    # apply a scaler on the features set\n",
    "    X = apply_scaler(scaler, X)\n",
    "    \n",
    "    # create sequences\n",
    "    X_seq, y_seq = create_seqs(X, y, timesteps)\n",
    "    \n",
    "    # source of inspiration: https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical [14]\n",
    "    # use to_categorical from tf to converts the target (trend) to binary class matrix, this will help us assign confidences to the classification prediction\n",
    "    if (target == \"classification\"):\n",
    "        y_seq = to_categorical(y_seq)\n",
    "\n",
    "    # devide the data into a training set and a test set in 70-30 ratio\n",
    "    training_ratio = int(len(X) * 0.7)\n",
    "    # add a vaidation ratio at 20% of the data, this will leave 10% as test\n",
    "    validation_ratio = int(len(X) * 0.2)\n",
    "    \n",
    "    X_train, X_vald, X_test = X_seq[:training_ratio], X_seq[training_ratio:training_ratio + validation_ratio], X_seq[training_ratio + validation_ratio:]\n",
    "    y_train, y_vald, y_test = y_seq[:training_ratio], y_seq[training_ratio:training_ratio + validation_ratio], y_seq[training_ratio + validation_ratio:]\n",
    "\n",
    "    # return the sets and the last_date\n",
    "    return X_train, X_vald, X_test, y_train, y_vald, y_test\n",
    "\n",
    "\n",
    "\n",
    "# initialize a MinMaxScaler instance for a range between 0 and 1\n",
    "min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# initialize a StandardScaler instance\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "# initialize a RobustScaler instance\n",
    "robust_scaler = RobustScaler()\n",
    "\n",
    "# X_train, X_test, y_train, y_test = create_train_test_sets(full_df, robust_scaler, \"classification\", 6)\n",
    "\n",
    "# X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ec2b17",
   "metadata": {},
   "source": [
    "# Apply the helper functions on all the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2a515e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that takes a dict of dataframes, and return a dict of training, validation and testing datasets\n",
    "def prepare_data_to_train(dfs_dict, scaler, target, timesteps):\n",
    "    \n",
    "    # create a dict of dicts to store training, validation and test sets for each stock\n",
    "    sets_dict = {}\n",
    "    \n",
    "    for symbol in dfs_dict.keys():\n",
    "        # add target columns to all the data frames\n",
    "        _df = add_targets(dfs_dict[symbol].copy(deep=True))\n",
    "        \n",
    "        # add technical indicators on the selected dataframe\n",
    "        _df = add_technical_indicators(_df)\n",
    "        \n",
    "        # convert the dataframe into training, validation and test sets\n",
    "        X_train, X_vald, X_test, y_train, y_vald, y_test = create_train_test_sets(_df, scaler, target, timesteps)\n",
    "        \n",
    "        # create a dict of the sets and add it to the sets_dict\n",
    "        sets_dict[symbol] = {\n",
    "            'X_train': X_train, 'X_vald': X_vald, 'X_test': X_test, \n",
    "            'y_train': y_train, 'y_vald': y_vald, 'y_test': y_test\n",
    "        }\n",
    "    \n",
    "    # return the sets\n",
    "    return sets_dict\n",
    "\n",
    "# set a list of options for the timesteps\n",
    "timesteps_options = list(range(4, 13))\n",
    "\n",
    "# create a dict to store the different timesteps datasets\n",
    "timesteps_options_dict = {}\n",
    "\n",
    "# iterate over the different timesteps\n",
    "for timesteps in timesteps_options:\n",
    "    \n",
    "    # call prepare_data_to_train on each option \n",
    "    data_set = prepare_data_to_train(dfs, standard_scaler, \"classification\", timesteps)\n",
    "    \n",
    "    \n",
    "    \n",
    "    timesteps_options_dict[timesteps] = data_set\n",
    "\n",
    "# timesteps_options_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dd9b725c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1817, 10, 72)\n",
      "(519, 10, 72)\n",
      "(250, 10, 72)\n"
     ]
    }
   ],
   "source": [
    "print(timesteps_options_dict[10]['PFE']['X_train'].shape)\n",
    "print(timesteps_options_dict[10]['PFE']['X_vald'].shape)\n",
    "print(timesteps_options_dict[10]['PFE']['X_test'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95813c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a881ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - 14ms/step - accuracy: 0.5000 - loss: 1.2652 - precision: 0.5000 - recall: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,768</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │           \u001b[38;5;34m8,768\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │             \u001b[38;5;34m130\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51,464</span> (201.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m51,464\u001b[0m (201.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,154</span> (67.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,154\u001b[0m (67.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,310</span> (134.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m34,310\u001b[0m (134.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Create and train the baseline classification model\n",
    "\n",
    "# source of inspiration: François Chollet (11, 2017), “Deep Learning with Python” chapter 6 [8]\n",
    "# construct the model\n",
    "def create_model(_timesteps, X_train_shape):\n",
    "    # initialize a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # add the model layers\n",
    "    # input layer\n",
    "    model.add(Input(shape=(_timesteps, X_train_shape[2])))\n",
    "    \n",
    "    model.add(SimpleRNN(64, return_sequences=True))\n",
    "    model.add(SimpleRNN(64, return_sequences=False))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='binary_crossentropy', # this is the most suitable one for prediction 0 or 1\n",
    "                  metrics=['precision', 'accuracy', 'recall'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# setup the data to be passed to the model\n",
    "X_train, y_train = timesteps_options_dict[5]['PFE']['X_train'], timesteps_options_dict[5]['PFE']['y_train']\n",
    "X_vald, y_vald = timesteps_options_dict[5]['PFE']['X_vald'], timesteps_options_dict[5]['PFE']['y_vald']\n",
    "X_test, y_test = timesteps_options_dict[5]['PFE']['X_test'], timesteps_options_dict[5]['PFE']['y_test']\n",
    "\n",
    "# initialize the model\n",
    "model1 = create_model(5, X_train.shape)\n",
    "\n",
    "# train the model\n",
    "history = model1.fit(X_train, y_train, validation_data=(X_vald, y_vald), epochs=20, batch_size=32, verbose=0)\n",
    "\n",
    "\n",
    "## Model evaluation and prototype conclusion\n",
    "\n",
    "# test the model accuracy\n",
    "model1.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "# list the model architecture\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "360a8fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.516417920589447,\n",
       "  0.6029850840568542,\n",
       "  0.6477611660957336,\n",
       "  0.6656716465950012,\n",
       "  0.6776119470596313,\n",
       "  0.7074626684188843,\n",
       "  0.7343283295631409,\n",
       "  0.7731343507766724,\n",
       "  0.7880597114562988,\n",
       "  0.8059701323509216,\n",
       "  0.8179104328155518,\n",
       "  0.8567163944244385,\n",
       "  0.8686566948890686,\n",
       "  0.8865671753883362,\n",
       "  0.8835821151733398,\n",
       "  0.9104477763175964,\n",
       "  0.9313432574272156,\n",
       "  0.9194029569625854,\n",
       "  0.9402984976768494,\n",
       "  0.9492537379264832],\n",
       " 'loss': [0.7300124168395996,\n",
       "  0.6656670570373535,\n",
       "  0.6402171850204468,\n",
       "  0.6169072985649109,\n",
       "  0.5946003794670105,\n",
       "  0.5734447240829468,\n",
       "  0.552064836025238,\n",
       "  0.5336057543754578,\n",
       "  0.5094841718673706,\n",
       "  0.48970332741737366,\n",
       "  0.4644557237625122,\n",
       "  0.42412129044532776,\n",
       "  0.3966217041015625,\n",
       "  0.3646836578845978,\n",
       "  0.3399151563644409,\n",
       "  0.3043617010116577,\n",
       "  0.2611752152442932,\n",
       "  0.23925387859344482,\n",
       "  0.22090932726860046,\n",
       "  0.1863139122724533],\n",
       " 'precision': [0.516417920589447,\n",
       "  0.6029850840568542,\n",
       "  0.6477611660957336,\n",
       "  0.6656716465950012,\n",
       "  0.6776119470596313,\n",
       "  0.7074626684188843,\n",
       "  0.7343283295631409,\n",
       "  0.7731343507766724,\n",
       "  0.7880597114562988,\n",
       "  0.8059701323509216,\n",
       "  0.8179104328155518,\n",
       "  0.8567163944244385,\n",
       "  0.8686566948890686,\n",
       "  0.8865671753883362,\n",
       "  0.8835821151733398,\n",
       "  0.9104477763175964,\n",
       "  0.9313432574272156,\n",
       "  0.9194029569625854,\n",
       "  0.9402984976768494,\n",
       "  0.9492537379264832],\n",
       " 'recall': [0.516417920589447,\n",
       "  0.6029850840568542,\n",
       "  0.6477611660957336,\n",
       "  0.6656716465950012,\n",
       "  0.6776119470596313,\n",
       "  0.7074626684188843,\n",
       "  0.7343283295631409,\n",
       "  0.7731343507766724,\n",
       "  0.7880597114562988,\n",
       "  0.8059701323509216,\n",
       "  0.8179104328155518,\n",
       "  0.8567163944244385,\n",
       "  0.8686566948890686,\n",
       "  0.8865671753883362,\n",
       "  0.8835821151733398,\n",
       "  0.9104477763175964,\n",
       "  0.9313432574272156,\n",
       "  0.9194029569625854,\n",
       "  0.9402984976768494,\n",
       "  0.9492537379264832],\n",
       " 'val_accuracy': [0.43157893419265747,\n",
       "  0.4000000059604645,\n",
       "  0.5473684072494507,\n",
       "  0.4000000059604645,\n",
       "  0.5263158082962036,\n",
       "  0.4000000059604645,\n",
       "  0.49473685026168823,\n",
       "  0.49473685026168823,\n",
       "  0.4526315927505493,\n",
       "  0.4842105209827423,\n",
       "  0.4842105209827423,\n",
       "  0.4842105209827423,\n",
       "  0.4842105209827423,\n",
       "  0.4421052634716034,\n",
       "  0.5052631497383118,\n",
       "  0.43157893419265747,\n",
       "  0.4421052634716034,\n",
       "  0.4421052634716034,\n",
       "  0.42105263471603394,\n",
       "  0.5052631497383118],\n",
       " 'val_loss': [0.7498762607574463,\n",
       "  0.7438854575157166,\n",
       "  0.7149105668067932,\n",
       "  0.774124801158905,\n",
       "  0.7370038628578186,\n",
       "  0.8032063245773315,\n",
       "  0.7537296414375305,\n",
       "  0.7953895330429077,\n",
       "  0.7799164056777954,\n",
       "  0.8168134093284607,\n",
       "  0.828377902507782,\n",
       "  0.8306644558906555,\n",
       "  0.8335747718811035,\n",
       "  0.9155231714248657,\n",
       "  0.9101148247718811,\n",
       "  0.9457734823226929,\n",
       "  1.055367350578308,\n",
       "  1.0283987522125244,\n",
       "  1.1402205228805542,\n",
       "  1.0219690799713135],\n",
       " 'val_precision': [0.43157893419265747,\n",
       "  0.4000000059604645,\n",
       "  0.5473684072494507,\n",
       "  0.4000000059604645,\n",
       "  0.5263158082962036,\n",
       "  0.4000000059604645,\n",
       "  0.49473685026168823,\n",
       "  0.49473685026168823,\n",
       "  0.4526315927505493,\n",
       "  0.4842105209827423,\n",
       "  0.4842105209827423,\n",
       "  0.4842105209827423,\n",
       "  0.4842105209827423,\n",
       "  0.4421052634716034,\n",
       "  0.5052631497383118,\n",
       "  0.43157893419265747,\n",
       "  0.4421052634716034,\n",
       "  0.4421052634716034,\n",
       "  0.42105263471603394,\n",
       "  0.5052631497383118],\n",
       " 'val_recall': [0.43157893419265747,\n",
       "  0.4000000059604645,\n",
       "  0.5473684072494507,\n",
       "  0.4000000059604645,\n",
       "  0.5263158082962036,\n",
       "  0.4000000059604645,\n",
       "  0.49473685026168823,\n",
       "  0.49473685026168823,\n",
       "  0.4526315927505493,\n",
       "  0.4842105209827423,\n",
       "  0.4842105209827423,\n",
       "  0.4842105209827423,\n",
       "  0.4842105209827423,\n",
       "  0.4421052634716034,\n",
       "  0.5052631497383118,\n",
       "  0.43157893419265747,\n",
       "  0.4421052634716034,\n",
       "  0.4421052634716034,\n",
       "  0.42105263471603394,\n",
       "  0.5052631497383118]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7db9e83",
   "metadata": {},
   "source": [
    "# create models archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90235ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - 12ms/step - accuracy: 0.4651 - loss: 1.0102 - precision: 0.4651 - recall: 0.4651\n",
      "2/2 - 1s - 344ms/step - accuracy: 0.5349 - loss: 0.9425 - precision: 0.5349 - recall: 0.5349\n",
      "2/2 - 0s - 221ms/step - accuracy: 0.6977 - loss: 0.9641 - precision: 0.6977 - recall: 0.6977\n",
      "2/2 - 1s - 264ms/step - accuracy: 0.5349 - loss: 1.1317 - precision: 0.5349 - recall: 0.5349\n",
      "2/2 - 1s - 302ms/step - accuracy: 0.5814 - loss: 1.0554 - precision: 0.5814 - recall: 0.5814\n"
     ]
    }
   ],
   "source": [
    "# create a function that takes a model creation function, dictionary of datasets as inputs, \n",
    "# and train the given model on these datasets one by one, then save the models to a dictionary where keys are stock symbols, \n",
    "# and values are dictionaries containing the models and meta data about the models\n",
    "def models_archive(_create_model, _dataset_dict, _timesteps, model_name):\n",
    "    \n",
    "    # create the models archive dictionary\n",
    "    archive = {}\n",
    "    \n",
    "    # get the datasets associated with the given timesteps \n",
    "    dataset_timestep = _dataset_dict[_timesteps]\n",
    "    \n",
    "    # iterate over the symbols in the dictionary\n",
    "    for symbol in dataset_timestep.keys():\n",
    "        \n",
    "        # initiate a dict for the symbol\n",
    "        archive[symbol] = {}\n",
    "        \n",
    "        # setup the data to be passed to the model\n",
    "        X_train, y_train = dataset_timestep[symbol]['X_train'], dataset_timestep[symbol]['y_train']\n",
    "        X_vald, y_vald = dataset_timestep[symbol]['X_vald'], dataset_timestep[symbol]['y_vald']\n",
    "        X_test, y_test = dataset_timestep[symbol]['X_test'], dataset_timestep[symbol]['y_test']\n",
    "\n",
    "        # initialize the model\n",
    "        model = _create_model(_timesteps, X_train.shape)\n",
    "\n",
    "        # train the model\n",
    "        history = model.fit(X_train, y_train, validation_data=(X_vald, y_vald), epochs=20, batch_size=32, verbose=0)\n",
    "\n",
    "        # source of inspiration: https://www.tensorflow.org/tutorials/keras/save_and_load\n",
    "        # save model to device\n",
    "        model.save(f'models/{model_name}_{symbol}.keras')        \n",
    "        \n",
    "        # store the model in the associated symbol dict\n",
    "        archive[symbol]['model'] = load_model(f'models/{model_name}_{symbol}.keras')\n",
    "        \n",
    "        # evaluate the model on the test_set and store it in the associated symbol dict\n",
    "        archive[symbol]['evaluation'] = model.evaluate(X_test, y_test, verbose=2)  \n",
    "        \n",
    "    return archive\n",
    "\n",
    "    \n",
    "stocks_model_archive = models_archive(create_model, timesteps_options_dict, 6, \"baseline_SimpleRNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "987779fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source of inspiration: deep learning with python. 7.2.2. Introduction to TensorBoard: the TensorFlow visualization framework. https://www.manning.com/books/deep-learning-with-python\n",
    "# plot the model\n",
    "# plot_model(stocks_model_archive['PFE']['model'], show_shapes=True, to_file=f'models/PFE_SimpleRNN.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61f14e1",
   "metadata": {},
   "source": [
    "# create model evaluation function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec8d420a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.562790697813034"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a function to calculate the precision, recall, and accuracy of a model\n",
    "def calculate_precision_recall_fscore(y_test, y_pred):\n",
    "    # source of inspiration: https://stackoverflow.com/questions/48987959/classification-metrics-cant-handle-a-mix-of-continuous-multioutput-and-multi-la [15]\n",
    "    # get precision, recall, and fscore\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "#     print(\"Precision:\", precision)\n",
    "#     print(\"Recall:\", recall)\n",
    "#     print(\"F-score:\", fscore)\n",
    "\n",
    "    return precision, recall, fscore\n",
    "\n",
    "# create a function that produce a confusion matrix of a model\n",
    "def create_confusion_matrix(y_test, y_pred):\n",
    "    # source of inspiration: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html [16]\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(conf_mat)\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "       \n",
    "# create a function that graph the traing vs validation loss\n",
    "def create_train_vald_graph(training_history): \n",
    "    # source of the code snippet[17]\n",
    "    # get the training and validation loss\n",
    "    loss = training_history['loss']\n",
    "    val_loss = training_history['val_loss']\n",
    "    \n",
    "    # we can get the number of epochs simply from the length of the loss list\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    \n",
    "    ### plot\n",
    "    plt.figure()\n",
    "    \n",
    "    # plot the training loss against the epochs\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    \n",
    "    # plot the validation loss against the epochs\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    \n",
    "    # add title and legend\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# create a function that takes a model archive (a dict of models) and calculate the average precision for all the models in it\n",
    "def evaluate_models_archive(_models_archive):\n",
    "    \n",
    "    # create a total precision variable and initialize it to 0\n",
    "    total_precision = 0\n",
    "    \n",
    "    # iterate over the symbols of the dictionary\n",
    "    for symbol in _models_archive.keys():\n",
    "        total_precision += _models_archive[symbol]['evaluation'][1]\n",
    "        \n",
    "    # calculate average precision\n",
    "    average_precision = total_precision / len(_models_archive.keys())\n",
    "    \n",
    "    return average_precision\n",
    "        \n",
    "evaluate_models_archive(stocks_model_archive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89c6f7e",
   "metadata": {},
   "source": [
    "# Hyperparameters optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390f6487",
   "metadata": {},
   "source": [
    "### hyperparameter optimization on SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f52f2916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source of inspiration: Introduction to the Keras Tuner, https://www.tensorflow.org/tutorials/keras/keras_tuner\n",
    "# constuct the model which will perform hyperparameter optimization to choose layers count, neurons counts, recurrent_dropout, optimizer_type, optimizer learning rate\n",
    "class HP_SimpleRNN_Model(HyperModel):\n",
    "\n",
    "    # initialize the model upon creating a class instance\n",
    "    # using a class structure instead of a function to construct the model will allow us to pass variables to it before passing it to keras tuner\n",
    "    # source of inspiration on how to pass variables to the model before passing the model to keras tuner: https://github.com/JulieProst/keras-tuner-tutorial/blob/master/hypermodels.py\n",
    "    def __init__(self, _timesteps, X_train_shape):\n",
    "        self.timesteps = _timesteps\n",
    "        self.X_train_shape = X_train_shape\n",
    "    \n",
    "    # build the model\n",
    "    def build(self, hp):\n",
    "        # initialize a sequential model\n",
    "        model = Sequential()\n",
    "\n",
    "        ### add the model layers (Model hyperparameters optimization)\n",
    "        # input layer\n",
    "        model.add(Input(shape=(self.timesteps, self.X_train_shape[2])))\n",
    "\n",
    "        # source: Int method, https://keras.io/api/keras_tuner/hyperparameters/\n",
    "        # dynamically optimize the number of layers\n",
    "        hp_layers = hp.Int(name='hp_layers', \n",
    "                           min_value=2, \n",
    "                           max_value=8, \n",
    "                           step=2)\n",
    "\n",
    "        # for each optimized layer\n",
    "        for i in range(hp_layers):\n",
    "\n",
    "            # dynamically tune the number of units in each layer, select a value between 32-256\n",
    "            hp_units = hp.Int(name=f'hp_units_at_hp_layer_{i}', \n",
    "                              min_value=32, \n",
    "                              max_value=256, \n",
    "                              step=32)\n",
    "            \n",
    "            # source: SimpleRNN layer, https://keras.io/api/layers/recurrent_layers/simple_rnn/\n",
    "            # return_sequences: Boolean. Whether to return the last output in the output sequence, or the full sequence. Default: False.\n",
    "            # set the return_sequences parameter to true unless it's the last layer, set it to false\n",
    "            return_sequences_boolean = i != (hp_layers - 1)\n",
    "\n",
    "            # source: Float method, https://keras.io/api/keras_tuner/hyperparameters/\n",
    "            # source: SimpleRNN layer, https://keras.io/api/layers/recurrent_layers/simple_rnn/\n",
    "            # recurrent_dropout: Float between 0 and 1. Fraction of the units to drop for the linear transformation of the recurrent state.\n",
    "            # dynamically tune the recurrent_dropout float value\n",
    "            recurrent_dropout = hp.Float(name=f'recurrent_dropout_{i}', \n",
    "                                         min_value=0.0, \n",
    "                                         max_value=0.5, \n",
    "                                         step=0.1)\n",
    "\n",
    "            # add a simpleRNN layer and pass the optimized number of unites, recurrent_dropout, and the return_sequences boolean\n",
    "            layer = SimpleRNN(units=hp_units, \n",
    "                              return_sequences=return_sequences_boolean, \n",
    "                              recurrent_dropout=recurrent_dropout)\n",
    "            model.add(layer)\n",
    "\n",
    "\n",
    "        # add the output layer\n",
    "        model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "        ### the model compiler (Algorithm hyperparameters optimization)\n",
    "        # source: Choice method, https://keras.io/api/keras_tuner/hyperparameters/\n",
    "        # dynamically optimize the optimizer type\n",
    "        hp_optimizer_type = hp.Choice('optimizer_type', values=['Adam', 'RMSprop', 'SGD'])\n",
    "        if hp_optimizer_type == 'Adam':\n",
    "            optimizer = Adam\n",
    "        elif hp_optimizer_type == 'RMSprop':\n",
    "            optimizer = RMSprop\n",
    "        else:\n",
    "            optimizer = SGD\n",
    "\n",
    "        # dynamically tune the learning rate for the optimizer\n",
    "        # When sampling=\"log\", the step is multiplied between samples.\n",
    "        hp_lr = hp.Float('learning_rate', \n",
    "                         min_value=0.0001, \n",
    "                         max_value=0.01, \n",
    "                         sampling='LOG')\n",
    "        hp_optimizer = optimizer(learning_rate=hp_lr)\n",
    "\n",
    "        # compile the model\n",
    "        model.compile(optimizer=hp_optimizer, \n",
    "                      loss='categorical_crossentropy', # this is the most suitable one for predictions of one-hot encoded labels\n",
    "                      metrics=['precision', 'accuracy', 'recall'])\n",
    "\n",
    "        # return the model\n",
    "        return model\n",
    "    \n",
    "    # source: omalleyt12, https://github.com/keras-team/keras-tuner/issues/122\n",
    "    # define a fit function which will allow us to pass an optimized value for batch_size\n",
    "    # *args and **kwargs are the ones we pass through tuner.search()\n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        \n",
    "        # dynamically optimize the batch_size for the training process\n",
    "        hp_batch_size = hp.Choice(\"batch_size\", [16, 32, 64, 128, 256])\n",
    "        return model.fit(\n",
    "            *args,\n",
    "            batch_size=hp_batch_size,\n",
    "            **kwargs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d02cbeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source of inspiration: Introduction to the Keras Tuner, https://www.tensorflow.org/tutorials/keras/keras_tuner\n",
    "# adjust the models_archive function to make it compatible with keras_tuner and hyperparameters optimization\n",
    "def hp_models_archive(_create_model, _dataset_dict, _timesteps, model_name):\n",
    "    \n",
    "    # get time before the training\n",
    "    start = get_time()\n",
    "    \n",
    "    # create the models archive dictionary\n",
    "    archive = {}\n",
    "    \n",
    "    # get the datasets associated with the given timesteps \n",
    "    dataset_timestep = _dataset_dict[_timesteps]\n",
    "    \n",
    "    # iterate over the symbols in the dictionary\n",
    "    for symbol in dataset_timestep.keys():\n",
    "        \n",
    "        # initiate a dict for the symbol\n",
    "        archive[symbol] = {}\n",
    "        \n",
    "        # setup the data to be passed to the model\n",
    "        X_train, y_train = dataset_timestep[symbol]['X_train'], dataset_timestep[symbol]['y_train']\n",
    "        X_vald, y_vald = dataset_timestep[symbol]['X_vald'], dataset_timestep[symbol]['y_vald']\n",
    "        X_test, y_test = dataset_timestep[symbol]['X_test'], dataset_timestep[symbol]['y_test']\n",
    "\n",
    "        # initialize the model\n",
    "        model = _create_model(_timesteps, X_train.shape)\n",
    "        \n",
    "        # source: Hyperband Tuner, https://keras.io/api/keras_tuner/tuners/hyperband/\n",
    "        ### Instantiate the tuner and perform hypertuning\n",
    "        # pass the model which is an Instance of HyperModel class (or callable that takes hyperparameters and returns a Model instance)\n",
    "        # objective is the direction of the optimization\n",
    "        # max_epochs is the maximum number of epochs to train one model, it is recommended to set this to a value slightly higher than expected then use early stopping callback during training (we will use the default value)\n",
    "        # factor: the reduction factor for the number of epochs and number of models for each bracket (we will use the default value)\n",
    "        # hyperband_iterations: the number of times to iterate over the full Hyperband algorithm. One iteration will run approximately max_epochs * (math.log(max_epochs, factor) ** 2) cumulative epochs across all trials. (we will use the default value)\n",
    "        # we will set the seed to make our work easier to replicate by others \n",
    "        # directory is and project name is the path where it will store the trails data results, this will make it much faster to rerun the training process if we need to\n",
    "        tuner = Hyperband(model, \n",
    "                          objective='val_precision', \n",
    "                          max_epochs=40, \n",
    "                          factor=3, \n",
    "                          hyperband_iterations=1, \n",
    "                          seed=101, \n",
    "                          directory='keras_tuner_models', \n",
    "                          project_name=f'hp_SimpleRNN2/{symbol}')\n",
    "\n",
    "        # source: EarlyStopping, https://keras.io/api/callbacks/early_stopping/\n",
    "        # Stop training when a monitored metric has stopped improving.\n",
    "        # Create a callback to stop training early after reaching a certain value for the validation loss.\n",
    "        # monitor: Quantity to be monitored.\n",
    "        # min_delta: Minimum change in the monitored quantity to qualify as an improvement (we will use the default value)\n",
    "        # patience: Number of epochs with no improvement after which training will be stopped.\n",
    "        stop_early = EarlyStopping(monitor='val_loss', \n",
    "                                   min_delta=0, \n",
    "                                   patience=5)\n",
    "\n",
    "        # Run the hyperparameter search. The arguments for the search method are the same as those used for tf.keras.model.fit in addition to the callback above.\n",
    "        tuner.search(X_train, y_train, \n",
    "                     epochs=50, \n",
    "                     validation_data=(X_vald, y_vald), \n",
    "                     callbacks=[stop_early])\n",
    "        \n",
    "        # source: The base Tuner class, https://keras.io/api/keras_tuner/tuners/base_tuner/\n",
    "        # get_best_hyperparameters Returns the best hyperparameters, as determined by the objective as a list sorted from the best to the worst.\n",
    "        # Get the optimal hyperparameters\n",
    "        best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "        \n",
    "        # Display tuning results summary. prints a summary of the search results including the hyperparameter values and evaluation results for each trial.\n",
    "        results_summary = tuner.results_summary()\n",
    "        \n",
    "        # Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "        model = tuner.hypermodel.build(best_hps)\n",
    "        history = model.fit(X_train, y_train, \n",
    "                            epochs=50, \n",
    "                            validation_data=(X_vald, y_vald), verbose=0)\n",
    "        \n",
    "        # get the history of val_precision during training as a list\n",
    "        val_prec_per_epoch = history.history['val_precision']\n",
    "        \n",
    "        # get the index of the highest val_precision from this list, we will use this index to set the epochs values during the training\n",
    "        best_epoch = val_prec_per_epoch.index(max(val_prec_per_epoch)) + 1\n",
    "        print('Best epoch: %d' % (best_epoch,))\n",
    "\n",
    "        ### train the model based on the results of the hyperparameter optimization process \n",
    "        # Re-instantiate the hypermodel and train it with the optimal number of epochs from above.\n",
    "        hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "        # Retrain the model\n",
    "#         hypermodel_history = hypermodel.fit(X_train, y_train, \n",
    "#                                             validation_data=(X_vald, y_vald), \n",
    "#                                             epochs=best_epoch, \n",
    "#                                             batch_size=32, verbose=0)\n",
    "        hypermodel_history = hypermodel.fit(X_train, y_train, \n",
    "                                            validation_data=(X_vald, y_vald), \n",
    "                                            epochs=best_epoch, \n",
    "                                            verbose=0)\n",
    "\n",
    "        # get predictions from the model given the test set\n",
    "        y_pred = hypermodel.predict(X_test)\n",
    "\n",
    "        # convert the predictions and test set to be in the shape of a vector of labels\n",
    "        y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "        y_test_labels = np.argmax(y_test, axis=1)\n",
    "        \n",
    "        # source of inspiration: https://www.tensorflow.org/tutorials/keras/save_and_load\n",
    "        # save model to device\n",
    "        hypermodel.save(f'models/{model_name}_{symbol}.keras')        \n",
    "        \n",
    "        # store the model in the associated symbol dict\n",
    "        archive[symbol]['model'] = load_model(f'models/{model_name}_{symbol}.keras')\n",
    "        \n",
    "        # evaluate the model on the test_set and store it in the associated symbol dict\n",
    "        archive[symbol]['evaluation'] = hypermodel.evaluate(X_test, y_test, verbose=0)\n",
    "        \n",
    "        # store the best model hyperparameters in the associated symbol dict\n",
    "        archive[symbol]['hyperparameters'] = best_hps\n",
    "        \n",
    "        # store the the best model training and validation accuracy history\n",
    "        archive[symbol]['training_history'] = hypermodel_history\n",
    "        \n",
    "        # store the the best model prediction labels and true labels\n",
    "        archive[symbol]['y_pred_labels'] = y_pred_labels\n",
    "        archive[symbol]['y_test_labels'] = y_test_labels\n",
    "        \n",
    "        # store the the tunning proccess results_summary\n",
    "        archive[symbol]['results_summary'] = results_summary\n",
    "        \n",
    "        # get time after the training\n",
    "        end = get_time()\n",
    "        \n",
    "        # print the trainig duration\n",
    "        print(f\"training for the {symbol} model was done in: {end - start}\")\n",
    "        \n",
    "    return archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03e2f3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to measure how long a process would take\n",
    "def get_time():\n",
    "    return datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10c920e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from keras_tuner_models\\hp_SimpleRNN2/PFE\\tuner0.json\n",
      "Results summary\n",
      "Results in keras_tuner_models\\hp_SimpleRNN2/PFE\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_precision\", direction=\"max\")\n",
      "\n",
      "Trial 0070 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 8\n",
      "hp_units_at_hp_layer_0: 224\n",
      "recurrent_dropout_0: 0.2\n",
      "hp_units_at_hp_layer_1: 128\n",
      "recurrent_dropout_1: 0.2\n",
      "optimizer_type: RMSprop\n",
      "learning_rate: 0.000493446318593248\n",
      "hp_units_at_hp_layer_2: 224\n",
      "recurrent_dropout_2: 0.2\n",
      "hp_units_at_hp_layer_3: 64\n",
      "recurrent_dropout_3: 0.30000000000000004\n",
      "hp_units_at_hp_layer_4: 96\n",
      "recurrent_dropout_4: 0.1\n",
      "hp_units_at_hp_layer_5: 256\n",
      "recurrent_dropout_5: 0.2\n",
      "batch_size: 16\n",
      "hp_units_at_hp_layer_6: 96\n",
      "recurrent_dropout_6: 0.2\n",
      "hp_units_at_hp_layer_7: 128\n",
      "recurrent_dropout_7: 0.0\n",
      "tuner/epochs: 14\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0064\n",
      "Score: 0.6421052813529968\n",
      "\n",
      "Trial 0013 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 4\n",
      "hp_units_at_hp_layer_0: 160\n",
      "recurrent_dropout_0: 0.0\n",
      "hp_units_at_hp_layer_1: 64\n",
      "recurrent_dropout_1: 0.1\n",
      "optimizer_type: SGD\n",
      "learning_rate: 0.0013182933088237972\n",
      "hp_units_at_hp_layer_2: 96\n",
      "recurrent_dropout_2: 0.4\n",
      "hp_units_at_hp_layer_3: 128\n",
      "recurrent_dropout_3: 0.4\n",
      "hp_units_at_hp_layer_4: 224\n",
      "recurrent_dropout_4: 0.4\n",
      "hp_units_at_hp_layer_5: 32\n",
      "recurrent_dropout_5: 0.1\n",
      "batch_size: 16\n",
      "hp_units_at_hp_layer_6: 192\n",
      "recurrent_dropout_6: 0.0\n",
      "hp_units_at_hp_layer_7: 224\n",
      "recurrent_dropout_7: 0.0\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 3\n",
      "tuner/round: 0\n",
      "Score: 0.6315789222717285\n",
      "\n",
      "Trial 0078 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 8\n",
      "hp_units_at_hp_layer_0: 128\n",
      "recurrent_dropout_0: 0.0\n",
      "hp_units_at_hp_layer_1: 192\n",
      "recurrent_dropout_1: 0.2\n",
      "optimizer_type: Adam\n",
      "learning_rate: 0.0026957402704483008\n",
      "hp_units_at_hp_layer_2: 256\n",
      "recurrent_dropout_2: 0.2\n",
      "hp_units_at_hp_layer_3: 160\n",
      "recurrent_dropout_3: 0.0\n",
      "hp_units_at_hp_layer_4: 64\n",
      "recurrent_dropout_4: 0.2\n",
      "hp_units_at_hp_layer_5: 32\n",
      "recurrent_dropout_5: 0.4\n",
      "batch_size: 16\n",
      "hp_units_at_hp_layer_6: 160\n",
      "recurrent_dropout_6: 0.2\n",
      "hp_units_at_hp_layer_7: 224\n",
      "recurrent_dropout_7: 0.0\n",
      "tuner/epochs: 14\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.6315789222717285\n",
      "\n",
      "Trial 0034 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 4\n",
      "hp_units_at_hp_layer_0: 160\n",
      "recurrent_dropout_0: 0.0\n",
      "hp_units_at_hp_layer_1: 64\n",
      "recurrent_dropout_1: 0.1\n",
      "optimizer_type: SGD\n",
      "learning_rate: 0.0013182933088237972\n",
      "hp_units_at_hp_layer_2: 96\n",
      "recurrent_dropout_2: 0.4\n",
      "hp_units_at_hp_layer_3: 128\n",
      "recurrent_dropout_3: 0.4\n",
      "hp_units_at_hp_layer_4: 224\n",
      "recurrent_dropout_4: 0.4\n",
      "hp_units_at_hp_layer_5: 32\n",
      "recurrent_dropout_5: 0.1\n",
      "batch_size: 16\n",
      "hp_units_at_hp_layer_6: 192\n",
      "recurrent_dropout_6: 0.0\n",
      "hp_units_at_hp_layer_7: 224\n",
      "recurrent_dropout_7: 0.0\n",
      "tuner/epochs: 5\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 3\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0013\n",
      "Score: 0.621052622795105\n",
      "\n",
      "Trial 0069 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 2\n",
      "hp_units_at_hp_layer_0: 160\n",
      "recurrent_dropout_0: 0.0\n",
      "hp_units_at_hp_layer_1: 128\n",
      "recurrent_dropout_1: 0.30000000000000004\n",
      "optimizer_type: Adam\n",
      "learning_rate: 0.00011250140614490984\n",
      "hp_units_at_hp_layer_2: 32\n",
      "recurrent_dropout_2: 0.2\n",
      "hp_units_at_hp_layer_3: 160\n",
      "recurrent_dropout_3: 0.4\n",
      "hp_units_at_hp_layer_4: 192\n",
      "recurrent_dropout_4: 0.1\n",
      "hp_units_at_hp_layer_5: 256\n",
      "recurrent_dropout_5: 0.4\n",
      "batch_size: 128\n",
      "hp_units_at_hp_layer_6: 128\n",
      "recurrent_dropout_6: 0.0\n",
      "hp_units_at_hp_layer_7: 32\n",
      "recurrent_dropout_7: 0.30000000000000004\n",
      "tuner/epochs: 14\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0065\n",
      "Score: 0.6105263233184814\n",
      "\n",
      "Trial 0067 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 2\n",
      "hp_units_at_hp_layer_0: 64\n",
      "recurrent_dropout_0: 0.30000000000000004\n",
      "hp_units_at_hp_layer_1: 160\n",
      "recurrent_dropout_1: 0.2\n",
      "optimizer_type: RMSprop\n",
      "learning_rate: 0.004123340146075227\n",
      "hp_units_at_hp_layer_2: 96\n",
      "recurrent_dropout_2: 0.2\n",
      "hp_units_at_hp_layer_3: 128\n",
      "recurrent_dropout_3: 0.30000000000000004\n",
      "hp_units_at_hp_layer_4: 192\n",
      "recurrent_dropout_4: 0.2\n",
      "hp_units_at_hp_layer_5: 224\n",
      "recurrent_dropout_5: 0.1\n",
      "batch_size: 64\n",
      "hp_units_at_hp_layer_6: 160\n",
      "recurrent_dropout_6: 0.4\n",
      "hp_units_at_hp_layer_7: 128\n",
      "recurrent_dropout_7: 0.4\n",
      "tuner/epochs: 14\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0053\n",
      "Score: 0.6105263233184814\n",
      "\n",
      "Trial 0025 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 6\n",
      "hp_units_at_hp_layer_0: 192\n",
      "recurrent_dropout_0: 0.1\n",
      "hp_units_at_hp_layer_1: 160\n",
      "recurrent_dropout_1: 0.2\n",
      "optimizer_type: Adam\n",
      "learning_rate: 0.0029860644714577917\n",
      "hp_units_at_hp_layer_2: 256\n",
      "recurrent_dropout_2: 0.30000000000000004\n",
      "hp_units_at_hp_layer_3: 32\n",
      "recurrent_dropout_3: 0.0\n",
      "hp_units_at_hp_layer_4: 160\n",
      "recurrent_dropout_4: 0.0\n",
      "hp_units_at_hp_layer_5: 256\n",
      "recurrent_dropout_5: 0.0\n",
      "batch_size: 256\n",
      "hp_units_at_hp_layer_6: 128\n",
      "recurrent_dropout_6: 0.0\n",
      "hp_units_at_hp_layer_7: 224\n",
      "recurrent_dropout_7: 0.30000000000000004\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 3\n",
      "tuner/round: 0\n",
      "Score: 0.6000000238418579\n",
      "\n",
      "Trial 0012 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 4\n",
      "hp_units_at_hp_layer_0: 96\n",
      "recurrent_dropout_0: 0.4\n",
      "hp_units_at_hp_layer_1: 192\n",
      "recurrent_dropout_1: 0.2\n",
      "optimizer_type: RMSprop\n",
      "learning_rate: 0.00016176530973716871\n",
      "hp_units_at_hp_layer_2: 224\n",
      "recurrent_dropout_2: 0.30000000000000004\n",
      "hp_units_at_hp_layer_3: 224\n",
      "recurrent_dropout_3: 0.4\n",
      "hp_units_at_hp_layer_4: 224\n",
      "recurrent_dropout_4: 0.1\n",
      "hp_units_at_hp_layer_5: 160\n",
      "recurrent_dropout_5: 0.4\n",
      "batch_size: 16\n",
      "hp_units_at_hp_layer_6: 32\n",
      "recurrent_dropout_6: 0.1\n",
      "hp_units_at_hp_layer_7: 32\n",
      "recurrent_dropout_7: 0.0\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 3\n",
      "tuner/round: 0\n",
      "Score: 0.6000000238418579\n",
      "\n",
      "Trial 0030 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 6\n",
      "hp_units_at_hp_layer_0: 128\n",
      "recurrent_dropout_0: 0.2\n",
      "hp_units_at_hp_layer_1: 128\n",
      "recurrent_dropout_1: 0.1\n",
      "optimizer_type: Adam\n",
      "learning_rate: 0.009343666641584668\n",
      "hp_units_at_hp_layer_2: 128\n",
      "recurrent_dropout_2: 0.4\n",
      "hp_units_at_hp_layer_3: 160\n",
      "recurrent_dropout_3: 0.1\n",
      "hp_units_at_hp_layer_4: 192\n",
      "recurrent_dropout_4: 0.4\n",
      "hp_units_at_hp_layer_5: 128\n",
      "recurrent_dropout_5: 0.30000000000000004\n",
      "batch_size: 32\n",
      "hp_units_at_hp_layer_6: 64\n",
      "recurrent_dropout_6: 0.0\n",
      "hp_units_at_hp_layer_7: 224\n",
      "recurrent_dropout_7: 0.1\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 3\n",
      "tuner/round: 0\n",
      "Score: 0.6000000238418579\n",
      "\n",
      "Trial 0026 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 8\n",
      "hp_units_at_hp_layer_0: 64\n",
      "recurrent_dropout_0: 0.2\n",
      "hp_units_at_hp_layer_1: 64\n",
      "recurrent_dropout_1: 0.0\n",
      "optimizer_type: Adam\n",
      "learning_rate: 0.0029533922569706128\n",
      "hp_units_at_hp_layer_2: 192\n",
      "recurrent_dropout_2: 0.0\n",
      "hp_units_at_hp_layer_3: 192\n",
      "recurrent_dropout_3: 0.2\n",
      "hp_units_at_hp_layer_4: 160\n",
      "recurrent_dropout_4: 0.4\n",
      "hp_units_at_hp_layer_5: 96\n",
      "recurrent_dropout_5: 0.1\n",
      "batch_size: 32\n",
      "hp_units_at_hp_layer_6: 32\n",
      "recurrent_dropout_6: 0.30000000000000004\n",
      "hp_units_at_hp_layer_7: 128\n",
      "recurrent_dropout_7: 0.2\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 3\n",
      "tuner/round: 0\n",
      "Score: 0.6000000238418579\n",
      "Best epoch: 16\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
      "training for the PFE model was done in: 0:00:44.508230\n",
      "Reloading Tuner from keras_tuner_models\\hp_SimpleRNN2/ROP\\tuner0.json\n",
      "Results summary\n",
      "Results in keras_tuner_models\\hp_SimpleRNN2/ROP\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_precision\", direction=\"max\")\n",
      "\n",
      "Trial 0067 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 6\n",
      "hp_units_at_hp_layer_0: 256\n",
      "recurrent_dropout_0: 0.0\n",
      "hp_units_at_hp_layer_1: 224\n",
      "recurrent_dropout_1: 0.2\n",
      "optimizer_type: SGD\n",
      "learning_rate: 0.0019545050901889393\n",
      "hp_units_at_hp_layer_2: 192\n",
      "recurrent_dropout_2: 0.1\n",
      "hp_units_at_hp_layer_3: 64\n",
      "recurrent_dropout_3: 0.4\n",
      "hp_units_at_hp_layer_4: 224\n",
      "recurrent_dropout_4: 0.2\n",
      "hp_units_at_hp_layer_5: 160\n",
      "recurrent_dropout_5: 0.2\n",
      "batch_size: 256\n",
      "hp_units_at_hp_layer_6: 64\n",
      "recurrent_dropout_6: 0.2\n",
      "hp_units_at_hp_layer_7: 128\n",
      "recurrent_dropout_7: 0.4\n",
      "tuner/epochs: 14\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0060\n",
      "Score: 0.6145833134651184\n",
      "\n",
      "Trial 0072 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 6\n",
      "hp_units_at_hp_layer_0: 256\n",
      "recurrent_dropout_0: 0.0\n",
      "hp_units_at_hp_layer_1: 224\n",
      "recurrent_dropout_1: 0.2\n",
      "optimizer_type: SGD\n",
      "learning_rate: 0.0019545050901889393\n",
      "hp_units_at_hp_layer_2: 192\n",
      "recurrent_dropout_2: 0.1\n",
      "hp_units_at_hp_layer_3: 64\n",
      "recurrent_dropout_3: 0.4\n",
      "hp_units_at_hp_layer_4: 224\n",
      "recurrent_dropout_4: 0.2\n",
      "hp_units_at_hp_layer_5: 160\n",
      "recurrent_dropout_5: 0.2\n",
      "batch_size: 256\n",
      "hp_units_at_hp_layer_6: 64\n",
      "recurrent_dropout_6: 0.2\n",
      "hp_units_at_hp_layer_7: 128\n",
      "recurrent_dropout_7: 0.4\n",
      "tuner/epochs: 40\n",
      "tuner/initial_epoch: 14\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0067\n",
      "Score: 0.6041666865348816\n",
      "\n",
      "Trial 0060 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 6\n",
      "hp_units_at_hp_layer_0: 256\n",
      "recurrent_dropout_0: 0.0\n",
      "hp_units_at_hp_layer_1: 224\n",
      "recurrent_dropout_1: 0.2\n",
      "optimizer_type: SGD\n",
      "learning_rate: 0.0019545050901889393\n",
      "hp_units_at_hp_layer_2: 192\n",
      "recurrent_dropout_2: 0.1\n",
      "hp_units_at_hp_layer_3: 64\n",
      "recurrent_dropout_3: 0.4\n",
      "hp_units_at_hp_layer_4: 224\n",
      "recurrent_dropout_4: 0.2\n",
      "hp_units_at_hp_layer_5: 160\n",
      "recurrent_dropout_5: 0.2\n",
      "batch_size: 256\n",
      "hp_units_at_hp_layer_6: 64\n",
      "recurrent_dropout_6: 0.2\n",
      "hp_units_at_hp_layer_7: 128\n",
      "recurrent_dropout_7: 0.4\n",
      "tuner/epochs: 5\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 2\n",
      "tuner/round: 0\n",
      "Score: 0.6041666865348816\n",
      "\n",
      "Trial 0027 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 2\n",
      "hp_units_at_hp_layer_0: 96\n",
      "recurrent_dropout_0: 0.1\n",
      "hp_units_at_hp_layer_1: 32\n",
      "recurrent_dropout_1: 0.0\n",
      "optimizer_type: SGD\n",
      "learning_rate: 0.0005382001266852058\n",
      "hp_units_at_hp_layer_2: 256\n",
      "recurrent_dropout_2: 0.4\n",
      "hp_units_at_hp_layer_3: 32\n",
      "recurrent_dropout_3: 0.4\n",
      "hp_units_at_hp_layer_4: 224\n",
      "recurrent_dropout_4: 0.1\n",
      "hp_units_at_hp_layer_5: 32\n",
      "recurrent_dropout_5: 0.0\n",
      "batch_size: 32\n",
      "hp_units_at_hp_layer_6: 64\n",
      "recurrent_dropout_6: 0.2\n",
      "hp_units_at_hp_layer_7: 192\n",
      "recurrent_dropout_7: 0.30000000000000004\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 3\n",
      "tuner/round: 0\n",
      "Score: 0.59375\n",
      "\n",
      "Trial 0034 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 2\n",
      "hp_units_at_hp_layer_0: 96\n",
      "recurrent_dropout_0: 0.1\n",
      "hp_units_at_hp_layer_1: 32\n",
      "recurrent_dropout_1: 0.0\n",
      "optimizer_type: SGD\n",
      "learning_rate: 0.0005382001266852058\n",
      "hp_units_at_hp_layer_2: 256\n",
      "recurrent_dropout_2: 0.4\n",
      "hp_units_at_hp_layer_3: 32\n",
      "recurrent_dropout_3: 0.4\n",
      "hp_units_at_hp_layer_4: 224\n",
      "recurrent_dropout_4: 0.1\n",
      "hp_units_at_hp_layer_5: 32\n",
      "recurrent_dropout_5: 0.0\n",
      "batch_size: 32\n",
      "hp_units_at_hp_layer_6: 64\n",
      "recurrent_dropout_6: 0.2\n",
      "hp_units_at_hp_layer_7: 192\n",
      "recurrent_dropout_7: 0.30000000000000004\n",
      "tuner/epochs: 5\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 3\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0027\n",
      "Score: 0.5833333134651184\n",
      "\n",
      "Trial 0031 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 2\n",
      "hp_units_at_hp_layer_0: 192\n",
      "recurrent_dropout_0: 0.30000000000000004\n",
      "hp_units_at_hp_layer_1: 32\n",
      "recurrent_dropout_1: 0.4\n",
      "optimizer_type: SGD\n",
      "learning_rate: 0.001775133820866207\n",
      "hp_units_at_hp_layer_2: 32\n",
      "recurrent_dropout_2: 0.0\n",
      "hp_units_at_hp_layer_3: 160\n",
      "recurrent_dropout_3: 0.1\n",
      "hp_units_at_hp_layer_4: 160\n",
      "recurrent_dropout_4: 0.1\n",
      "hp_units_at_hp_layer_5: 128\n",
      "recurrent_dropout_5: 0.30000000000000004\n",
      "batch_size: 64\n",
      "hp_units_at_hp_layer_6: 64\n",
      "recurrent_dropout_6: 0.1\n",
      "hp_units_at_hp_layer_7: 96\n",
      "recurrent_dropout_7: 0.1\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 3\n",
      "tuner/round: 0\n",
      "Score: 0.5729166865348816\n",
      "\n",
      "Trial 0048 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 6\n",
      "hp_units_at_hp_layer_0: 64\n",
      "recurrent_dropout_0: 0.30000000000000004\n",
      "hp_units_at_hp_layer_1: 96\n",
      "recurrent_dropout_1: 0.0\n",
      "optimizer_type: SGD\n",
      "learning_rate: 0.000929184356170649\n",
      "hp_units_at_hp_layer_2: 128\n",
      "recurrent_dropout_2: 0.4\n",
      "hp_units_at_hp_layer_3: 160\n",
      "recurrent_dropout_3: 0.30000000000000004\n",
      "hp_units_at_hp_layer_4: 224\n",
      "recurrent_dropout_4: 0.1\n",
      "hp_units_at_hp_layer_5: 192\n",
      "recurrent_dropout_5: 0.1\n",
      "batch_size: 32\n",
      "hp_units_at_hp_layer_6: 192\n",
      "recurrent_dropout_6: 0.30000000000000004\n",
      "hp_units_at_hp_layer_7: 224\n",
      "recurrent_dropout_7: 0.0\n",
      "tuner/epochs: 14\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 3\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0036\n",
      "Score: 0.5729166865348816\n",
      "\n",
      "Trial 0046 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 2\n",
      "hp_units_at_hp_layer_0: 96\n",
      "recurrent_dropout_0: 0.1\n",
      "hp_units_at_hp_layer_1: 32\n",
      "recurrent_dropout_1: 0.0\n",
      "optimizer_type: SGD\n",
      "learning_rate: 0.0005382001266852058\n",
      "hp_units_at_hp_layer_2: 256\n",
      "recurrent_dropout_2: 0.4\n",
      "hp_units_at_hp_layer_3: 32\n",
      "recurrent_dropout_3: 0.4\n",
      "hp_units_at_hp_layer_4: 224\n",
      "recurrent_dropout_4: 0.1\n",
      "hp_units_at_hp_layer_5: 32\n",
      "recurrent_dropout_5: 0.0\n",
      "batch_size: 32\n",
      "hp_units_at_hp_layer_6: 64\n",
      "recurrent_dropout_6: 0.2\n",
      "hp_units_at_hp_layer_7: 192\n",
      "recurrent_dropout_7: 0.30000000000000004\n",
      "tuner/epochs: 14\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 3\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0034\n",
      "Score: 0.5729166865348816\n",
      "\n",
      "Trial 0087 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 2\n",
      "hp_units_at_hp_layer_0: 32\n",
      "recurrent_dropout_0: 0.0\n",
      "hp_units_at_hp_layer_1: 256\n",
      "recurrent_dropout_1: 0.0\n",
      "optimizer_type: Adam\n",
      "learning_rate: 0.008795300828358128\n",
      "hp_units_at_hp_layer_2: 32\n",
      "recurrent_dropout_2: 0.0\n",
      "hp_units_at_hp_layer_3: 192\n",
      "recurrent_dropout_3: 0.2\n",
      "hp_units_at_hp_layer_4: 96\n",
      "recurrent_dropout_4: 0.1\n",
      "hp_units_at_hp_layer_5: 224\n",
      "recurrent_dropout_5: 0.0\n",
      "batch_size: 128\n",
      "hp_units_at_hp_layer_6: 64\n",
      "recurrent_dropout_6: 0.1\n",
      "hp_units_at_hp_layer_7: 32\n",
      "recurrent_dropout_7: 0.30000000000000004\n",
      "tuner/epochs: 40\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.5729166865348816\n",
      "\n",
      "Trial 0050 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 2\n",
      "hp_units_at_hp_layer_0: 96\n",
      "recurrent_dropout_0: 0.1\n",
      "hp_units_at_hp_layer_1: 32\n",
      "recurrent_dropout_1: 0.0\n",
      "optimizer_type: SGD\n",
      "learning_rate: 0.0005382001266852058\n",
      "hp_units_at_hp_layer_2: 256\n",
      "recurrent_dropout_2: 0.4\n",
      "hp_units_at_hp_layer_3: 32\n",
      "recurrent_dropout_3: 0.4\n",
      "hp_units_at_hp_layer_4: 224\n",
      "recurrent_dropout_4: 0.1\n",
      "hp_units_at_hp_layer_5: 32\n",
      "recurrent_dropout_5: 0.0\n",
      "batch_size: 32\n",
      "hp_units_at_hp_layer_6: 64\n",
      "recurrent_dropout_6: 0.2\n",
      "hp_units_at_hp_layer_7: 192\n",
      "recurrent_dropout_7: 0.30000000000000004\n",
      "tuner/epochs: 40\n",
      "tuner/initial_epoch: 14\n",
      "tuner/bracket: 3\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0046\n",
      "Score: 0.5729166865348816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 37\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 869ms/step\n",
      "training for the ROP model was done in: 0:01:24.529075\n",
      "Reloading Tuner from keras_tuner_models\\hp_SimpleRNN2/XYL\\tuner0.json\n",
      "Results summary\n",
      "Results in keras_tuner_models\\hp_SimpleRNN2/XYL\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_precision\", direction=\"max\")\n",
      "\n",
      "Trial 0046 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 2\n",
      "hp_units_at_hp_layer_0: 32\n",
      "recurrent_dropout_0: 0.30000000000000004\n",
      "hp_units_at_hp_layer_1: 32\n",
      "recurrent_dropout_1: 0.1\n",
      "optimizer_type: RMSprop\n",
      "learning_rate: 0.00010406284012562844\n",
      "hp_units_at_hp_layer_2: 160\n",
      "recurrent_dropout_2: 0.1\n",
      "hp_units_at_hp_layer_3: 160\n",
      "recurrent_dropout_3: 0.1\n",
      "hp_units_at_hp_layer_4: 160\n",
      "recurrent_dropout_4: 0.1\n",
      "hp_units_at_hp_layer_5: 64\n",
      "recurrent_dropout_5: 0.2\n",
      "batch_size: 16\n",
      "hp_units_at_hp_layer_6: 224\n",
      "recurrent_dropout_6: 0.4\n",
      "hp_units_at_hp_layer_7: 96\n",
      "recurrent_dropout_7: 0.30000000000000004\n",
      "tuner/epochs: 14\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 3\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0039\n",
      "Score: 0.6145833134651184\n",
      "\n",
      "Trial 0080 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 4\n",
      "hp_units_at_hp_layer_0: 96\n",
      "recurrent_dropout_0: 0.30000000000000004\n",
      "hp_units_at_hp_layer_1: 96\n",
      "recurrent_dropout_1: 0.2\n",
      "optimizer_type: Adam\n",
      "learning_rate: 0.00033676743541390575\n",
      "hp_units_at_hp_layer_2: 192\n",
      "recurrent_dropout_2: 0.2\n",
      "hp_units_at_hp_layer_3: 160\n",
      "recurrent_dropout_3: 0.2\n",
      "hp_units_at_hp_layer_4: 128\n",
      "recurrent_dropout_4: 0.30000000000000004\n",
      "hp_units_at_hp_layer_5: 96\n",
      "recurrent_dropout_5: 0.30000000000000004\n",
      "batch_size: 32\n",
      "hp_units_at_hp_layer_6: 64\n",
      "recurrent_dropout_6: 0.4\n",
      "hp_units_at_hp_layer_7: 96\n",
      "recurrent_dropout_7: 0.4\n",
      "tuner/epochs: 14\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.6145833134651184\n",
      "\n",
      "Trial 0050 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 2\n",
      "hp_units_at_hp_layer_0: 32\n",
      "recurrent_dropout_0: 0.30000000000000004\n",
      "hp_units_at_hp_layer_1: 32\n",
      "recurrent_dropout_1: 0.1\n",
      "optimizer_type: RMSprop\n",
      "learning_rate: 0.00010406284012562844\n",
      "hp_units_at_hp_layer_2: 160\n",
      "recurrent_dropout_2: 0.1\n",
      "hp_units_at_hp_layer_3: 160\n",
      "recurrent_dropout_3: 0.1\n",
      "hp_units_at_hp_layer_4: 160\n",
      "recurrent_dropout_4: 0.1\n",
      "hp_units_at_hp_layer_5: 64\n",
      "recurrent_dropout_5: 0.2\n",
      "batch_size: 16\n",
      "hp_units_at_hp_layer_6: 224\n",
      "recurrent_dropout_6: 0.4\n",
      "hp_units_at_hp_layer_7: 96\n",
      "recurrent_dropout_7: 0.30000000000000004\n",
      "tuner/epochs: 40\n",
      "tuner/initial_epoch: 14\n",
      "tuner/bracket: 3\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0046\n",
      "Score: 0.6041666865348816\n",
      "\n",
      "Trial 0072 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 4\n",
      "hp_units_at_hp_layer_0: 192\n",
      "recurrent_dropout_0: 0.1\n",
      "hp_units_at_hp_layer_1: 256\n",
      "recurrent_dropout_1: 0.4\n",
      "optimizer_type: Adam\n",
      "learning_rate: 0.0001164331764071064\n",
      "hp_units_at_hp_layer_2: 256\n",
      "recurrent_dropout_2: 0.4\n",
      "hp_units_at_hp_layer_3: 128\n",
      "recurrent_dropout_3: 0.4\n",
      "hp_units_at_hp_layer_4: 96\n",
      "recurrent_dropout_4: 0.30000000000000004\n",
      "hp_units_at_hp_layer_5: 64\n",
      "recurrent_dropout_5: 0.4\n",
      "batch_size: 64\n",
      "hp_units_at_hp_layer_6: 224\n",
      "recurrent_dropout_6: 0.30000000000000004\n",
      "hp_units_at_hp_layer_7: 256\n",
      "recurrent_dropout_7: 0.2\n",
      "tuner/epochs: 40\n",
      "tuner/initial_epoch: 14\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0067\n",
      "Score: 0.6041666865348816\n",
      "\n",
      "Trial 0086 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 6\n",
      "hp_units_at_hp_layer_0: 160\n",
      "recurrent_dropout_0: 0.0\n",
      "hp_units_at_hp_layer_1: 192\n",
      "recurrent_dropout_1: 0.1\n",
      "optimizer_type: RMSprop\n",
      "learning_rate: 0.00021521854610047315\n",
      "hp_units_at_hp_layer_2: 224\n",
      "recurrent_dropout_2: 0.2\n",
      "hp_units_at_hp_layer_3: 160\n",
      "recurrent_dropout_3: 0.0\n",
      "hp_units_at_hp_layer_4: 192\n",
      "recurrent_dropout_4: 0.30000000000000004\n",
      "hp_units_at_hp_layer_5: 192\n",
      "recurrent_dropout_5: 0.2\n",
      "batch_size: 32\n",
      "hp_units_at_hp_layer_6: 160\n",
      "recurrent_dropout_6: 0.2\n",
      "hp_units_at_hp_layer_7: 64\n",
      "recurrent_dropout_7: 0.1\n",
      "tuner/epochs: 40\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.6041666865348816\n",
      "\n",
      "Trial 0039 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 2\n",
      "hp_units_at_hp_layer_0: 32\n",
      "recurrent_dropout_0: 0.30000000000000004\n",
      "hp_units_at_hp_layer_1: 32\n",
      "recurrent_dropout_1: 0.1\n",
      "optimizer_type: RMSprop\n",
      "learning_rate: 0.00010406284012562844\n",
      "hp_units_at_hp_layer_2: 160\n",
      "recurrent_dropout_2: 0.1\n",
      "hp_units_at_hp_layer_3: 160\n",
      "recurrent_dropout_3: 0.1\n",
      "hp_units_at_hp_layer_4: 160\n",
      "recurrent_dropout_4: 0.1\n",
      "hp_units_at_hp_layer_5: 64\n",
      "recurrent_dropout_5: 0.2\n",
      "batch_size: 16\n",
      "hp_units_at_hp_layer_6: 224\n",
      "recurrent_dropout_6: 0.4\n",
      "hp_units_at_hp_layer_7: 96\n",
      "recurrent_dropout_7: 0.30000000000000004\n",
      "tuner/epochs: 5\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 3\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0006\n",
      "Score: 0.59375\n",
      "\n",
      "Trial 0088 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 8\n",
      "hp_units_at_hp_layer_0: 64\n",
      "recurrent_dropout_0: 0.0\n",
      "hp_units_at_hp_layer_1: 96\n",
      "recurrent_dropout_1: 0.2\n",
      "optimizer_type: Adam\n",
      "learning_rate: 0.00046710314559090724\n",
      "hp_units_at_hp_layer_2: 128\n",
      "recurrent_dropout_2: 0.4\n",
      "hp_units_at_hp_layer_3: 160\n",
      "recurrent_dropout_3: 0.4\n",
      "hp_units_at_hp_layer_4: 160\n",
      "recurrent_dropout_4: 0.2\n",
      "hp_units_at_hp_layer_5: 96\n",
      "recurrent_dropout_5: 0.4\n",
      "batch_size: 16\n",
      "hp_units_at_hp_layer_6: 128\n",
      "recurrent_dropout_6: 0.2\n",
      "hp_units_at_hp_layer_7: 256\n",
      "recurrent_dropout_7: 0.1\n",
      "tuner/epochs: 40\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.59375\n",
      "\n",
      "Trial 0062 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 4\n",
      "hp_units_at_hp_layer_0: 192\n",
      "recurrent_dropout_0: 0.1\n",
      "hp_units_at_hp_layer_1: 256\n",
      "recurrent_dropout_1: 0.4\n",
      "optimizer_type: Adam\n",
      "learning_rate: 0.0001164331764071064\n",
      "hp_units_at_hp_layer_2: 256\n",
      "recurrent_dropout_2: 0.4\n",
      "hp_units_at_hp_layer_3: 128\n",
      "recurrent_dropout_3: 0.4\n",
      "hp_units_at_hp_layer_4: 96\n",
      "recurrent_dropout_4: 0.30000000000000004\n",
      "hp_units_at_hp_layer_5: 64\n",
      "recurrent_dropout_5: 0.4\n",
      "batch_size: 64\n",
      "hp_units_at_hp_layer_6: 224\n",
      "recurrent_dropout_6: 0.30000000000000004\n",
      "hp_units_at_hp_layer_7: 256\n",
      "recurrent_dropout_7: 0.2\n",
      "tuner/epochs: 5\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 2\n",
      "tuner/round: 0\n",
      "Score: 0.5833333134651184\n",
      "\n",
      "Trial 0067 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 4\n",
      "hp_units_at_hp_layer_0: 192\n",
      "recurrent_dropout_0: 0.1\n",
      "hp_units_at_hp_layer_1: 256\n",
      "recurrent_dropout_1: 0.4\n",
      "optimizer_type: Adam\n",
      "learning_rate: 0.0001164331764071064\n",
      "hp_units_at_hp_layer_2: 256\n",
      "recurrent_dropout_2: 0.4\n",
      "hp_units_at_hp_layer_3: 128\n",
      "recurrent_dropout_3: 0.4\n",
      "hp_units_at_hp_layer_4: 96\n",
      "recurrent_dropout_4: 0.30000000000000004\n",
      "hp_units_at_hp_layer_5: 64\n",
      "recurrent_dropout_5: 0.4\n",
      "batch_size: 64\n",
      "hp_units_at_hp_layer_6: 224\n",
      "recurrent_dropout_6: 0.30000000000000004\n",
      "hp_units_at_hp_layer_7: 256\n",
      "recurrent_dropout_7: 0.2\n",
      "tuner/epochs: 14\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0062\n",
      "Score: 0.5833333134651184\n",
      "\n",
      "Trial 0009 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 2\n",
      "hp_units_at_hp_layer_0: 128\n",
      "recurrent_dropout_0: 0.1\n",
      "hp_units_at_hp_layer_1: 192\n",
      "recurrent_dropout_1: 0.30000000000000004\n",
      "optimizer_type: SGD\n",
      "learning_rate: 0.008553027379762107\n",
      "hp_units_at_hp_layer_2: 64\n",
      "recurrent_dropout_2: 0.30000000000000004\n",
      "hp_units_at_hp_layer_3: 32\n",
      "recurrent_dropout_3: 0.4\n",
      "hp_units_at_hp_layer_4: 128\n",
      "recurrent_dropout_4: 0.4\n",
      "hp_units_at_hp_layer_5: 64\n",
      "recurrent_dropout_5: 0.0\n",
      "batch_size: 128\n",
      "hp_units_at_hp_layer_6: 96\n",
      "recurrent_dropout_6: 0.4\n",
      "hp_units_at_hp_layer_7: 256\n",
      "recurrent_dropout_7: 0.2\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 3\n",
      "tuner/round: 0\n",
      "Score: 0.5729166865348816\n",
      "Best epoch: 4\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001EF09D771A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 363ms/stepWARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001EF09D771A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 317ms/step\n",
      "training for the XYL model was done in: 0:01:42.694821\n",
      "Reloading Tuner from keras_tuner_models\\hp_SimpleRNN2/CPAY\\tuner0.json\n",
      "Results summary\n",
      "Results in keras_tuner_models\\hp_SimpleRNN2/CPAY\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_precision\", direction=\"max\")\n",
      "\n",
      "Trial 0082 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 2\n",
      "hp_units_at_hp_layer_0: 160\n",
      "recurrent_dropout_0: 0.0\n",
      "hp_units_at_hp_layer_1: 64\n",
      "recurrent_dropout_1: 0.1\n",
      "optimizer_type: SGD\n",
      "learning_rate: 0.005977428471215702\n",
      "hp_units_at_hp_layer_2: 32\n",
      "recurrent_dropout_2: 0.2\n",
      "hp_units_at_hp_layer_3: 256\n",
      "recurrent_dropout_3: 0.1\n",
      "hp_units_at_hp_layer_4: 32\n",
      "recurrent_dropout_4: 0.4\n",
      "hp_units_at_hp_layer_5: 96\n",
      "recurrent_dropout_5: 0.4\n",
      "batch_size: 64\n",
      "hp_units_at_hp_layer_6: 96\n",
      "recurrent_dropout_6: 0.30000000000000004\n",
      "hp_units_at_hp_layer_7: 32\n",
      "recurrent_dropout_7: 0.2\n",
      "tuner/epochs: 40\n",
      "tuner/initial_epoch: 14\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0074\n",
      "Score: 0.6458333134651184\n",
      "\n",
      "Trial 0069 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 2\n",
      "hp_units_at_hp_layer_0: 160\n",
      "recurrent_dropout_0: 0.0\n",
      "hp_units_at_hp_layer_1: 128\n",
      "recurrent_dropout_1: 0.30000000000000004\n",
      "optimizer_type: Adam\n",
      "learning_rate: 0.00011250140614490984\n",
      "hp_units_at_hp_layer_2: 32\n",
      "recurrent_dropout_2: 0.2\n",
      "hp_units_at_hp_layer_3: 160\n",
      "recurrent_dropout_3: 0.4\n",
      "hp_units_at_hp_layer_4: 192\n",
      "recurrent_dropout_4: 0.1\n",
      "hp_units_at_hp_layer_5: 256\n",
      "recurrent_dropout_5: 0.4\n",
      "batch_size: 128\n",
      "hp_units_at_hp_layer_6: 128\n",
      "recurrent_dropout_6: 0.0\n",
      "hp_units_at_hp_layer_7: 32\n",
      "recurrent_dropout_7: 0.30000000000000004\n",
      "tuner/epochs: 14\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0065\n",
      "Score: 0.625\n",
      "\n",
      "Trial 0074 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 2\n",
      "hp_units_at_hp_layer_0: 160\n",
      "recurrent_dropout_0: 0.0\n",
      "hp_units_at_hp_layer_1: 64\n",
      "recurrent_dropout_1: 0.1\n",
      "optimizer_type: SGD\n",
      "learning_rate: 0.005977428471215702\n",
      "hp_units_at_hp_layer_2: 32\n",
      "recurrent_dropout_2: 0.2\n",
      "hp_units_at_hp_layer_3: 256\n",
      "recurrent_dropout_3: 0.1\n",
      "hp_units_at_hp_layer_4: 32\n",
      "recurrent_dropout_4: 0.4\n",
      "hp_units_at_hp_layer_5: 96\n",
      "recurrent_dropout_5: 0.4\n",
      "batch_size: 64\n",
      "hp_units_at_hp_layer_6: 96\n",
      "recurrent_dropout_6: 0.30000000000000004\n",
      "hp_units_at_hp_layer_7: 32\n",
      "recurrent_dropout_7: 0.2\n",
      "tuner/epochs: 14\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.625\n",
      "\n",
      "Trial 0075 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 8\n",
      "hp_units_at_hp_layer_0: 128\n",
      "recurrent_dropout_0: 0.0\n",
      "hp_units_at_hp_layer_1: 64\n",
      "recurrent_dropout_1: 0.30000000000000004\n",
      "optimizer_type: RMSprop\n",
      "learning_rate: 0.006771864336530797\n",
      "hp_units_at_hp_layer_2: 64\n",
      "recurrent_dropout_2: 0.2\n",
      "hp_units_at_hp_layer_3: 96\n",
      "recurrent_dropout_3: 0.2\n",
      "hp_units_at_hp_layer_4: 96\n",
      "recurrent_dropout_4: 0.30000000000000004\n",
      "hp_units_at_hp_layer_5: 96\n",
      "recurrent_dropout_5: 0.2\n",
      "batch_size: 32\n",
      "hp_units_at_hp_layer_6: 192\n",
      "recurrent_dropout_6: 0.2\n",
      "hp_units_at_hp_layer_7: 64\n",
      "recurrent_dropout_7: 0.2\n",
      "tuner/epochs: 14\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.6145833134651184\n",
      "\n",
      "Trial 0067 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 2\n",
      "hp_units_at_hp_layer_0: 64\n",
      "recurrent_dropout_0: 0.30000000000000004\n",
      "hp_units_at_hp_layer_1: 160\n",
      "recurrent_dropout_1: 0.2\n",
      "optimizer_type: RMSprop\n",
      "learning_rate: 0.004123340146075227\n",
      "hp_units_at_hp_layer_2: 96\n",
      "recurrent_dropout_2: 0.2\n",
      "hp_units_at_hp_layer_3: 128\n",
      "recurrent_dropout_3: 0.30000000000000004\n",
      "hp_units_at_hp_layer_4: 192\n",
      "recurrent_dropout_4: 0.2\n",
      "hp_units_at_hp_layer_5: 224\n",
      "recurrent_dropout_5: 0.1\n",
      "batch_size: 64\n",
      "hp_units_at_hp_layer_6: 160\n",
      "recurrent_dropout_6: 0.4\n",
      "hp_units_at_hp_layer_7: 128\n",
      "recurrent_dropout_7: 0.4\n",
      "tuner/epochs: 14\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0053\n",
      "Score: 0.6145833134651184\n",
      "\n",
      "Trial 0072 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 2\n",
      "hp_units_at_hp_layer_0: 160\n",
      "recurrent_dropout_0: 0.0\n",
      "hp_units_at_hp_layer_1: 128\n",
      "recurrent_dropout_1: 0.30000000000000004\n",
      "optimizer_type: Adam\n",
      "learning_rate: 0.00011250140614490984\n",
      "hp_units_at_hp_layer_2: 32\n",
      "recurrent_dropout_2: 0.2\n",
      "hp_units_at_hp_layer_3: 160\n",
      "recurrent_dropout_3: 0.4\n",
      "hp_units_at_hp_layer_4: 192\n",
      "recurrent_dropout_4: 0.1\n",
      "hp_units_at_hp_layer_5: 256\n",
      "recurrent_dropout_5: 0.4\n",
      "batch_size: 128\n",
      "hp_units_at_hp_layer_6: 128\n",
      "recurrent_dropout_6: 0.0\n",
      "hp_units_at_hp_layer_7: 32\n",
      "recurrent_dropout_7: 0.30000000000000004\n",
      "tuner/epochs: 40\n",
      "tuner/initial_epoch: 14\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0069\n",
      "Score: 0.6041666865348816\n",
      "\n",
      "Trial 0002 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 8\n",
      "hp_units_at_hp_layer_0: 256\n",
      "recurrent_dropout_0: 0.2\n",
      "hp_units_at_hp_layer_1: 32\n",
      "recurrent_dropout_1: 0.4\n",
      "optimizer_type: RMSprop\n",
      "learning_rate: 0.0010953574938066576\n",
      "hp_units_at_hp_layer_2: 96\n",
      "recurrent_dropout_2: 0.2\n",
      "hp_units_at_hp_layer_3: 128\n",
      "recurrent_dropout_3: 0.2\n",
      "hp_units_at_hp_layer_4: 192\n",
      "recurrent_dropout_4: 0.2\n",
      "hp_units_at_hp_layer_5: 32\n",
      "recurrent_dropout_5: 0.0\n",
      "batch_size: 16\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 3\n",
      "tuner/round: 0\n",
      "hp_units_at_hp_layer_6: 32\n",
      "recurrent_dropout_6: 0.0\n",
      "hp_units_at_hp_layer_7: 32\n",
      "recurrent_dropout_7: 0.0\n",
      "Score: 0.59375\n",
      "\n",
      "Trial 0018 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 2\n",
      "hp_units_at_hp_layer_0: 64\n",
      "recurrent_dropout_0: 0.1\n",
      "hp_units_at_hp_layer_1: 224\n",
      "recurrent_dropout_1: 0.1\n",
      "optimizer_type: RMSprop\n",
      "learning_rate: 0.003755429065882092\n",
      "hp_units_at_hp_layer_2: 128\n",
      "recurrent_dropout_2: 0.1\n",
      "hp_units_at_hp_layer_3: 64\n",
      "recurrent_dropout_3: 0.0\n",
      "hp_units_at_hp_layer_4: 32\n",
      "recurrent_dropout_4: 0.1\n",
      "hp_units_at_hp_layer_5: 64\n",
      "recurrent_dropout_5: 0.1\n",
      "batch_size: 256\n",
      "hp_units_at_hp_layer_6: 192\n",
      "recurrent_dropout_6: 0.30000000000000004\n",
      "hp_units_at_hp_layer_7: 32\n",
      "recurrent_dropout_7: 0.4\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 3\n",
      "tuner/round: 0\n",
      "Score: 0.59375\n",
      "\n",
      "Trial 0022 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 8\n",
      "hp_units_at_hp_layer_0: 32\n",
      "recurrent_dropout_0: 0.0\n",
      "hp_units_at_hp_layer_1: 256\n",
      "recurrent_dropout_1: 0.1\n",
      "optimizer_type: SGD\n",
      "learning_rate: 0.009917974979603957\n",
      "hp_units_at_hp_layer_2: 256\n",
      "recurrent_dropout_2: 0.30000000000000004\n",
      "hp_units_at_hp_layer_3: 192\n",
      "recurrent_dropout_3: 0.4\n",
      "hp_units_at_hp_layer_4: 256\n",
      "recurrent_dropout_4: 0.1\n",
      "hp_units_at_hp_layer_5: 128\n",
      "recurrent_dropout_5: 0.2\n",
      "batch_size: 16\n",
      "hp_units_at_hp_layer_6: 192\n",
      "recurrent_dropout_6: 0.30000000000000004\n",
      "hp_units_at_hp_layer_7: 96\n",
      "recurrent_dropout_7: 0.1\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 3\n",
      "tuner/round: 0\n",
      "Score: 0.59375\n",
      "\n",
      "Trial 0048 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 6\n",
      "hp_units_at_hp_layer_0: 64\n",
      "recurrent_dropout_0: 0.30000000000000004\n",
      "hp_units_at_hp_layer_1: 96\n",
      "recurrent_dropout_1: 0.0\n",
      "optimizer_type: SGD\n",
      "learning_rate: 0.000929184356170649\n",
      "hp_units_at_hp_layer_2: 128\n",
      "recurrent_dropout_2: 0.4\n",
      "hp_units_at_hp_layer_3: 160\n",
      "recurrent_dropout_3: 0.30000000000000004\n",
      "hp_units_at_hp_layer_4: 224\n",
      "recurrent_dropout_4: 0.1\n",
      "hp_units_at_hp_layer_5: 192\n",
      "recurrent_dropout_5: 0.1\n",
      "batch_size: 32\n",
      "hp_units_at_hp_layer_6: 192\n",
      "recurrent_dropout_6: 0.30000000000000004\n",
      "hp_units_at_hp_layer_7: 224\n",
      "recurrent_dropout_7: 0.0\n",
      "tuner/epochs: 14\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 3\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0039\n",
      "Score: 0.59375\n",
      "Best epoch: 8\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 358ms/step\n",
      "training for the CPAY model was done in: 0:01:58.468181\n",
      "Reloading Tuner from keras_tuner_models\\hp_SimpleRNN2/INCY\\tuner0.json\n",
      "Results summary\n",
      "Results in keras_tuner_models\\hp_SimpleRNN2/INCY\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_precision\", direction=\"max\")\n",
      "\n",
      "Trial 0081 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 8\n",
      "hp_units_at_hp_layer_0: 64\n",
      "recurrent_dropout_0: 0.1\n",
      "hp_units_at_hp_layer_1: 224\n",
      "recurrent_dropout_1: 0.1\n",
      "optimizer_type: RMSprop\n",
      "learning_rate: 0.0004659670189886583\n",
      "hp_units_at_hp_layer_2: 192\n",
      "recurrent_dropout_2: 0.0\n",
      "hp_units_at_hp_layer_3: 224\n",
      "recurrent_dropout_3: 0.0\n",
      "hp_units_at_hp_layer_4: 96\n",
      "recurrent_dropout_4: 0.30000000000000004\n",
      "hp_units_at_hp_layer_5: 160\n",
      "recurrent_dropout_5: 0.4\n",
      "batch_size: 64\n",
      "hp_units_at_hp_layer_6: 160\n",
      "recurrent_dropout_6: 0.4\n",
      "hp_units_at_hp_layer_7: 160\n",
      "recurrent_dropout_7: 0.4\n",
      "tuner/epochs: 14\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.6354166865348816\n",
      "\n",
      "Trial 0088 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 8\n",
      "hp_units_at_hp_layer_0: 64\n",
      "recurrent_dropout_0: 0.0\n",
      "hp_units_at_hp_layer_1: 96\n",
      "recurrent_dropout_1: 0.2\n",
      "optimizer_type: Adam\n",
      "learning_rate: 0.00046710314559090724\n",
      "hp_units_at_hp_layer_2: 128\n",
      "recurrent_dropout_2: 0.4\n",
      "hp_units_at_hp_layer_3: 160\n",
      "recurrent_dropout_3: 0.4\n",
      "hp_units_at_hp_layer_4: 160\n",
      "recurrent_dropout_4: 0.2\n",
      "hp_units_at_hp_layer_5: 96\n",
      "recurrent_dropout_5: 0.4\n",
      "batch_size: 16\n",
      "hp_units_at_hp_layer_6: 128\n",
      "recurrent_dropout_6: 0.2\n",
      "hp_units_at_hp_layer_7: 256\n",
      "recurrent_dropout_7: 0.1\n",
      "tuner/epochs: 40\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.6145833134651184\n",
      "\n",
      "Trial 0050 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 4\n",
      "hp_units_at_hp_layer_0: 128\n",
      "recurrent_dropout_0: 0.4\n",
      "hp_units_at_hp_layer_1: 64\n",
      "recurrent_dropout_1: 0.0\n",
      "optimizer_type: Adam\n",
      "learning_rate: 0.0006950772468507907\n",
      "hp_units_at_hp_layer_2: 192\n",
      "recurrent_dropout_2: 0.30000000000000004\n",
      "hp_units_at_hp_layer_3: 224\n",
      "recurrent_dropout_3: 0.0\n",
      "hp_units_at_hp_layer_4: 64\n",
      "recurrent_dropout_4: 0.1\n",
      "hp_units_at_hp_layer_5: 224\n",
      "recurrent_dropout_5: 0.2\n",
      "batch_size: 128\n",
      "hp_units_at_hp_layer_6: 96\n",
      "recurrent_dropout_6: 0.4\n",
      "hp_units_at_hp_layer_7: 96\n",
      "recurrent_dropout_7: 0.30000000000000004\n",
      "tuner/epochs: 40\n",
      "tuner/initial_epoch: 14\n",
      "tuner/bracket: 3\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 0049\n",
      "Score: 0.6145833134651184\n",
      "\n",
      "Trial 0089 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 4\n",
      "hp_units_at_hp_layer_0: 224\n",
      "recurrent_dropout_0: 0.4\n",
      "hp_units_at_hp_layer_1: 96\n",
      "recurrent_dropout_1: 0.1\n",
      "optimizer_type: Adam\n",
      "learning_rate: 0.003722759302364584\n",
      "hp_units_at_hp_layer_2: 160\n",
      "recurrent_dropout_2: 0.2\n",
      "hp_units_at_hp_layer_3: 128\n",
      "recurrent_dropout_3: 0.4\n",
      "hp_units_at_hp_layer_4: 64\n",
      "recurrent_dropout_4: 0.2\n",
      "hp_units_at_hp_layer_5: 256\n",
      "recurrent_dropout_5: 0.1\n",
      "batch_size: 32\n",
      "hp_units_at_hp_layer_6: 64\n",
      "recurrent_dropout_6: 0.30000000000000004\n",
      "hp_units_at_hp_layer_7: 224\n",
      "recurrent_dropout_7: 0.2\n",
      "tuner/epochs: 40\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.6041666865348816\n",
      "\n",
      "Trial 0049 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 4\n",
      "hp_units_at_hp_layer_0: 128\n",
      "recurrent_dropout_0: 0.4\n",
      "hp_units_at_hp_layer_1: 64\n",
      "recurrent_dropout_1: 0.0\n",
      "optimizer_type: Adam\n",
      "learning_rate: 0.0006950772468507907\n",
      "hp_units_at_hp_layer_2: 192\n",
      "recurrent_dropout_2: 0.30000000000000004\n",
      "hp_units_at_hp_layer_3: 224\n",
      "recurrent_dropout_3: 0.0\n",
      "hp_units_at_hp_layer_4: 64\n",
      "recurrent_dropout_4: 0.1\n",
      "hp_units_at_hp_layer_5: 224\n",
      "recurrent_dropout_5: 0.2\n",
      "batch_size: 128\n",
      "hp_units_at_hp_layer_6: 96\n",
      "recurrent_dropout_6: 0.4\n",
      "hp_units_at_hp_layer_7: 96\n",
      "recurrent_dropout_7: 0.30000000000000004\n",
      "tuner/epochs: 14\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 3\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0036\n",
      "Score: 0.6041666865348816\n",
      "\n",
      "Trial 0069 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 6\n",
      "hp_units_at_hp_layer_0: 32\n",
      "recurrent_dropout_0: 0.2\n",
      "hp_units_at_hp_layer_1: 32\n",
      "recurrent_dropout_1: 0.2\n",
      "optimizer_type: RMSprop\n",
      "learning_rate: 0.007034231509360318\n",
      "hp_units_at_hp_layer_2: 96\n",
      "recurrent_dropout_2: 0.1\n",
      "hp_units_at_hp_layer_3: 32\n",
      "recurrent_dropout_3: 0.30000000000000004\n",
      "hp_units_at_hp_layer_4: 32\n",
      "recurrent_dropout_4: 0.0\n",
      "hp_units_at_hp_layer_5: 256\n",
      "recurrent_dropout_5: 0.30000000000000004\n",
      "batch_size: 256\n",
      "hp_units_at_hp_layer_6: 64\n",
      "recurrent_dropout_6: 0.0\n",
      "hp_units_at_hp_layer_7: 128\n",
      "recurrent_dropout_7: 0.1\n",
      "tuner/epochs: 14\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0054\n",
      "Score: 0.6041666865348816\n",
      "\n",
      "Trial 0085 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 4\n",
      "hp_units_at_hp_layer_0: 32\n",
      "recurrent_dropout_0: 0.2\n",
      "hp_units_at_hp_layer_1: 256\n",
      "recurrent_dropout_1: 0.0\n",
      "optimizer_type: RMSprop\n",
      "learning_rate: 0.0008194969626209\n",
      "hp_units_at_hp_layer_2: 160\n",
      "recurrent_dropout_2: 0.0\n",
      "hp_units_at_hp_layer_3: 64\n",
      "recurrent_dropout_3: 0.2\n",
      "hp_units_at_hp_layer_4: 128\n",
      "recurrent_dropout_4: 0.2\n",
      "hp_units_at_hp_layer_5: 96\n",
      "recurrent_dropout_5: 0.4\n",
      "batch_size: 256\n",
      "hp_units_at_hp_layer_6: 160\n",
      "recurrent_dropout_6: 0.0\n",
      "hp_units_at_hp_layer_7: 32\n",
      "recurrent_dropout_7: 0.0\n",
      "tuner/epochs: 40\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.6041666865348816\n",
      "\n",
      "Trial 0006 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 2\n",
      "hp_units_at_hp_layer_0: 32\n",
      "recurrent_dropout_0: 0.30000000000000004\n",
      "hp_units_at_hp_layer_1: 32\n",
      "recurrent_dropout_1: 0.1\n",
      "optimizer_type: RMSprop\n",
      "learning_rate: 0.00010406284012562844\n",
      "hp_units_at_hp_layer_2: 160\n",
      "recurrent_dropout_2: 0.1\n",
      "hp_units_at_hp_layer_3: 160\n",
      "recurrent_dropout_3: 0.1\n",
      "hp_units_at_hp_layer_4: 160\n",
      "recurrent_dropout_4: 0.1\n",
      "hp_units_at_hp_layer_5: 64\n",
      "recurrent_dropout_5: 0.2\n",
      "batch_size: 16\n",
      "hp_units_at_hp_layer_6: 224\n",
      "recurrent_dropout_6: 0.4\n",
      "hp_units_at_hp_layer_7: 96\n",
      "recurrent_dropout_7: 0.30000000000000004\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 3\n",
      "tuner/round: 0\n",
      "Score: 0.59375\n",
      "\n",
      "Trial 0046 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 8\n",
      "hp_units_at_hp_layer_0: 256\n",
      "recurrent_dropout_0: 0.2\n",
      "hp_units_at_hp_layer_1: 32\n",
      "recurrent_dropout_1: 0.4\n",
      "optimizer_type: RMSprop\n",
      "learning_rate: 0.0010953574938066576\n",
      "hp_units_at_hp_layer_2: 96\n",
      "recurrent_dropout_2: 0.2\n",
      "hp_units_at_hp_layer_3: 128\n",
      "recurrent_dropout_3: 0.2\n",
      "hp_units_at_hp_layer_4: 192\n",
      "recurrent_dropout_4: 0.2\n",
      "hp_units_at_hp_layer_5: 32\n",
      "recurrent_dropout_5: 0.0\n",
      "batch_size: 16\n",
      "tuner/epochs: 14\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 3\n",
      "tuner/round: 2\n",
      "hp_units_at_hp_layer_6: 32\n",
      "recurrent_dropout_6: 0.0\n",
      "hp_units_at_hp_layer_7: 32\n",
      "recurrent_dropout_7: 0.0\n",
      "tuner/trial_id: 0035\n",
      "Score: 0.59375\n",
      "\n",
      "Trial 0086 summary\n",
      "Hyperparameters:\n",
      "hp_layers: 6\n",
      "hp_units_at_hp_layer_0: 160\n",
      "recurrent_dropout_0: 0.0\n",
      "hp_units_at_hp_layer_1: 192\n",
      "recurrent_dropout_1: 0.1\n",
      "optimizer_type: RMSprop\n",
      "learning_rate: 0.00021521854610047315\n",
      "hp_units_at_hp_layer_2: 224\n",
      "recurrent_dropout_2: 0.2\n",
      "hp_units_at_hp_layer_3: 160\n",
      "recurrent_dropout_3: 0.0\n",
      "hp_units_at_hp_layer_4: 192\n",
      "recurrent_dropout_4: 0.30000000000000004\n",
      "hp_units_at_hp_layer_5: 192\n",
      "recurrent_dropout_5: 0.2\n",
      "batch_size: 32\n",
      "hp_units_at_hp_layer_6: 160\n",
      "recurrent_dropout_6: 0.2\n",
      "hp_units_at_hp_layer_7: 64\n",
      "recurrent_dropout_7: 0.1\n",
      "tuner/epochs: 40\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.59375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 2\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
      "training for the INCY model was done in: 0:02:39.846968\n"
     ]
    }
   ],
   "source": [
    "# build the models archive for all the stock symbols using the HP_SimpleRNN_Model\n",
    "hp_stocks_SRNN_model_archive = hp_models_archive(HP_SimpleRNN_Model, timesteps_options_dict, 6, \"hp_SimpleRNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aaf55b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5767441868782044"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_models_archive(hp_stocks_SRNN_model_archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a7355d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the model\n",
    "# plot_model(hp_stocks_SRNN_model_archive['PFE']['model'], show_shapes=True, to_file=f'models/PFE_hp_SimpleRNN.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8ca86372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for symbol in hp_stocks_SRNN_model_archive.keys():\n",
    "#     hp_stocks_SRNN_model_archive[symbol]['model'].summary()\n",
    "#     print(\"------ symbol -----\", hp_stocks_SRNN_model_archive[symbol]['hyperparameters'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "623fa353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">84,224</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">107,744</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">80,064</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">64,736</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">61,600</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">322</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn_34 (\u001b[38;5;33mSimpleRNN\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │          \u001b[38;5;34m84,224\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_35 (\u001b[38;5;33mSimpleRNN\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m224\u001b[0m)              │         \u001b[38;5;34m107,744\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_36 (\u001b[38;5;33mSimpleRNN\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m192\u001b[0m)              │          \u001b[38;5;34m80,064\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_37 (\u001b[38;5;33mSimpleRNN\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │          \u001b[38;5;34m16,448\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_38 (\u001b[38;5;33mSimpleRNN\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m224\u001b[0m)              │          \u001b[38;5;34m64,736\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_39 (\u001b[38;5;33mSimpleRNN\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m)                 │          \u001b[38;5;34m61,600\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │             \u001b[38;5;34m322\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">415,140</span> (1.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m415,140\u001b[0m (1.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">415,138</span> (1.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m415,138\u001b[0m (1.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hp_stocks_SRNN_model_archive['ROP']['model'].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c5193e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PFE': {'model': <Sequential name=sequential_7, built=True>,\n",
       "  'evaluation': [0.8233613967895508,\n",
       "   0.5581395626068115,\n",
       "   0.5581395626068115,\n",
       "   0.5581395626068115],\n",
       "  'hyperparameters': <keras_tuner.src.engine.hyperparameters.hyperparameters.HyperParameters at 0x1ef67b3d650>,\n",
       "  'training_history': <keras.src.callbacks.history.History at 0x1ef6f052350>,\n",
       "  'y_pred_labels': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1],\n",
       "        dtype=int64),\n",
       "  'y_test_labels': array([0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "         1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1],\n",
       "        dtype=int64),\n",
       "  'results_summary': None},\n",
       " 'ROP': {'model': <Sequential name=sequential_9, built=True>,\n",
       "  'evaluation': [0.6911514401435852,\n",
       "   0.5813953280448914,\n",
       "   0.5813953280448914,\n",
       "   0.5813953280448914],\n",
       "  'hyperparameters': <keras_tuner.src.engine.hyperparameters.hyperparameters.HyperParameters at 0x1ef78b34c90>,\n",
       "  'training_history': <keras.src.callbacks.history.History at 0x1ef7fd8d750>,\n",
       "  'y_pred_labels': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        dtype=int64),\n",
       "  'y_test_labels': array([0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "         1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0],\n",
       "        dtype=int64),\n",
       "  'results_summary': None},\n",
       " 'XYL': {'model': <Sequential name=sequential_11, built=True>,\n",
       "  'evaluation': [0.6585419178009033,\n",
       "   0.6744186282157898,\n",
       "   0.6744186282157898,\n",
       "   0.6744186282157898],\n",
       "  'hyperparameters': <keras_tuner.src.engine.hyperparameters.hyperparameters.HyperParameters at 0x1ef086407d0>,\n",
       "  'training_history': <keras.src.callbacks.history.History at 0x1ef6f06e910>,\n",
       "  'y_pred_labels': array([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        dtype=int64),\n",
       "  'y_test_labels': array([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "         1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1],\n",
       "        dtype=int64),\n",
       "  'results_summary': None},\n",
       " 'CPAY': {'model': <Sequential name=sequential_13, built=True>,\n",
       "  'evaluation': [0.6775612235069275,\n",
       "   0.5813953280448914,\n",
       "   0.5813953280448914,\n",
       "   0.5813953280448914],\n",
       "  'hyperparameters': <keras_tuner.src.engine.hyperparameters.hyperparameters.HyperParameters at 0x1ef0b366550>,\n",
       "  'training_history': <keras.src.callbacks.history.History at 0x1ef0e84c110>,\n",
       "  'y_pred_labels': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1],\n",
       "        dtype=int64),\n",
       "  'y_test_labels': array([0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "         1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1],\n",
       "        dtype=int64),\n",
       "  'results_summary': None},\n",
       " 'INCY': {'model': <Sequential name=sequential_15, built=True>,\n",
       "  'evaluation': [0.8301250338554382,\n",
       "   0.4883720874786377,\n",
       "   0.4883720874786377,\n",
       "   0.4883720874786377],\n",
       "  'hyperparameters': <keras_tuner.src.engine.hyperparameters.hyperparameters.HyperParameters at 0x1ef110b3690>,\n",
       "  'training_history': <keras.src.callbacks.history.History at 0x1ef1c6440d0>,\n",
       "  'y_pred_labels': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        dtype=int64),\n",
       "  'y_test_labels': array([0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1],\n",
       "        dtype=int64),\n",
       "  'results_summary': None}}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_stocks_SRNN_model_archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dfd2839a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hp_layers': 6,\n",
       " 'hp_units_at_hp_layer_0': 256,\n",
       " 'recurrent_dropout_0': 0.0,\n",
       " 'hp_units_at_hp_layer_1': 224,\n",
       " 'recurrent_dropout_1': 0.2,\n",
       " 'optimizer_type': 'SGD',\n",
       " 'learning_rate': 0.0019545050901889393,\n",
       " 'hp_units_at_hp_layer_2': 192,\n",
       " 'recurrent_dropout_2': 0.1,\n",
       " 'hp_units_at_hp_layer_3': 64,\n",
       " 'recurrent_dropout_3': 0.4,\n",
       " 'hp_units_at_hp_layer_4': 224,\n",
       " 'recurrent_dropout_4': 0.2,\n",
       " 'hp_units_at_hp_layer_5': 160,\n",
       " 'recurrent_dropout_5': 0.2,\n",
       " 'batch_size': 256,\n",
       " 'hp_units_at_hp_layer_6': 64,\n",
       " 'recurrent_dropout_6': 0.2,\n",
       " 'hp_units_at_hp_layer_7': 128,\n",
       " 'recurrent_dropout_7': 0.4,\n",
       " 'tuner/epochs': 14,\n",
       " 'tuner/initial_epoch': 5,\n",
       " 'tuner/bracket': 2,\n",
       " 'tuner/round': 1,\n",
       " 'tuner/trial_id': '0060'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_stocks_SRNN_model_archive['ROP']['hyperparameters'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6b6606a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # setup the data to be passed to the model\n",
    "# X_train, y_train = timesteps_options_dict[6]['XYL']['X_train'], timesteps_options_dict[6]['XYL']['y_train']\n",
    "# X_vald, y_vald = timesteps_options_dict[6]['XYL']['X_vald'], timesteps_options_dict[6]['XYL']['y_vald']\n",
    "# X_test, y_test = timesteps_options_dict[6]['XYL']['X_test'], timesteps_options_dict[6]['XYL']['y_test']\n",
    "\n",
    "# test_mod = HP_SimpleRNN_Model(6, X_train.shape)\n",
    "\n",
    "# test_or = Oracle()\n",
    "\n",
    "# test_hp = hp_stocks_SRNN_model_archive['XYL']['hyperparameters']\n",
    "\n",
    "# test_tun = Hyperband(test_mod, seed=101)\n",
    "# test_hypermodel = test_tun.hypermodel.build(test_hp)\n",
    "\n",
    "\n",
    "# # Retrain the model\n",
    "# test_hist = test_hypermodel.fit(X_train, y_train, \n",
    "#                                     validation_data=(X_vald, y_vald), \n",
    "#                                     epochs=50, verbose=0)\n",
    "\n",
    "# test_hypermodel.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fc4030",
   "metadata": {},
   "source": [
    "# Manual Tunning\n",
    "### BatchNormalization and Depthwise separable convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3ad0f520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_73\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_73\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ separable_conv1d_24                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,552</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv1D</span>)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_174              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_313 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,984</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_175              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_314 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">107,744</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_176              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_315 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">80,064</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_177              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_316 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_178              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_317 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">64,736</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_179              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_318 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">61,600</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_180              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">322</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ separable_conv1d_24                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │           \u001b[38;5;34m2,552\u001b[0m │\n",
       "│ (\u001b[38;5;33mSeparableConv1D\u001b[0m)                    │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_174              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_12 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m32\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_313 (\u001b[38;5;33mSimpleRNN\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │          \u001b[38;5;34m73,984\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_175              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_314 (\u001b[38;5;33mSimpleRNN\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m224\u001b[0m)              │         \u001b[38;5;34m107,744\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_176              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m224\u001b[0m)              │             \u001b[38;5;34m896\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_315 (\u001b[38;5;33mSimpleRNN\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m192\u001b[0m)              │          \u001b[38;5;34m80,064\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_177              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m192\u001b[0m)              │             \u001b[38;5;34m768\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_316 (\u001b[38;5;33mSimpleRNN\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │          \u001b[38;5;34m16,448\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_178              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_317 (\u001b[38;5;33mSimpleRNN\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m224\u001b[0m)              │          \u001b[38;5;34m64,736\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_179              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m224\u001b[0m)              │             \u001b[38;5;34m896\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_318 (\u001b[38;5;33mSimpleRNN\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m)                 │          \u001b[38;5;34m61,600\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_180              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m)                 │             \u001b[38;5;34m640\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_69 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │             \u001b[38;5;34m322\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">412,060</span> (1.57 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m412,060\u001b[0m (1.57 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">409,754</span> (1.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m409,754\u001b[0m (1.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> (9.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,304\u001b[0m (9.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_SimpleRNN_extra_layers(_timesteps, X_train_shape):\n",
    "    # initialize a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # add the model layers\n",
    "    # input layer\n",
    "    model.add(Input(shape=(_timesteps, X_train_shape[2])))\n",
    "    \n",
    "    model.add(SeparableConv1D(filters=32, \n",
    "                              kernel_size=3, \n",
    "                              strides=1, \n",
    "                              padding='same', \n",
    "                              activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    # source: MaxPooling1D layer, https://keras.io/api/layers/pooling_layers/max_pooling1d/\n",
    "    # Max pooling operation for 1D temporal data. Downsamples the input representation by taking the maximum value over a spatial window of size pool_size. The window is shifted by strides.\n",
    "    model.add(MaxPooling1D())\n",
    "\n",
    "    \n",
    "    model.add(SimpleRNN(256, return_sequences=True))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(SimpleRNN(224, return_sequences=True, recurrent_dropout=0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(SimpleRNN(192, return_sequences=True, recurrent_dropout=0.1))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(SimpleRNN(64, return_sequences=True, recurrent_dropout=0.4))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(SimpleRNN(224, return_sequences=True, recurrent_dropout=0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(SimpleRNN(160, return_sequences=False, recurrent_dropout=0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    # compile the model\n",
    "    optimizer = SGD(learning_rate=0.0019545050901889393)\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['precision', 'accuracy', 'recall'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# setup the data to be passed to the model\n",
    "X_train, y_train = timesteps_options_dict[10]['ROP']['X_train'], timesteps_options_dict[10]['ROP']['y_train']\n",
    "X_vald, y_vald = timesteps_options_dict[10]['ROP']['X_vald'], timesteps_options_dict[10]['ROP']['y_vald']\n",
    "X_test, y_test = timesteps_options_dict[10]['ROP']['X_test'], timesteps_options_dict[10]['ROP']['y_test']\n",
    "\n",
    "# initialize the model\n",
    "model1 = create_SimpleRNN_extra_layers(10, X_train.shape)\n",
    "\n",
    "# train the model\n",
    "history = model1.fit(X_train, y_train, validation_data=(X_vald, y_vald), epochs=50, batch_size=256, verbose=0)\n",
    "\n",
    "\n",
    "## Model evaluation and prototype conclusion\n",
    "\n",
    "# test the model accuracy\n",
    "model1.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# list the model architecture\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "460ac4d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7120890617370605,\n",
       " 0.5686274766921997,\n",
       " 0.5686274766921997,\n",
       " 0.5686274766921997]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0a7665",
   "metadata": {},
   "source": [
    "### functional API and residual connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "384f91b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7214826941490173, 0.522292971611023, 0.522292971611023, 0.522292971611023]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_SimpleRNN_functional_residual(_timesteps, X_train_shape):\n",
    "    \n",
    "    # add the model layers\n",
    "    # input layer\n",
    "    input_data = Input(shape=(_timesteps, X_train_shape[2]))\n",
    "    \n",
    "    y = SeparableConv1D(filters=32, \n",
    "                              kernel_size=3, \n",
    "                              strides=1, \n",
    "                              padding='same', \n",
    "                              activation='relu')(input_data)\n",
    "    y = BatchNormalization()(y)\n",
    "    # source: MaxPooling1D layer, https://keras.io/api/layers/pooling_layers/max_pooling1d/\n",
    "    # Max pooling operation for 1D temporal data. Downsamples the input representation by taking the maximum value over a spatial window of size pool_size. The window is shifted by strides.\n",
    "    y = MaxPooling1D()(y)\n",
    "    \n",
    "    x = SimpleRNN(256, return_sequences=True)(y)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = SimpleRNN(224, return_sequences=True, recurrent_dropout=0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = SimpleRNN(192, return_sequences=True, recurrent_dropout=0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = SimpleRNN(64, return_sequences=True, recurrent_dropout=0.4)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = SimpleRNN(224, return_sequences=True, recurrent_dropout=0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    y2 = SeparableConv1D(filters=32, \n",
    "                              kernel_size=3, \n",
    "                              strides=1, \n",
    "                              padding='same', \n",
    "                              activation='relu')(x)\n",
    "    y2 = BatchNormalization()(y2)\n",
    "    y2 = MaxPooling1D()(y2)\n",
    "    \n",
    "    residual = add([y, y2])\n",
    "\n",
    "    \n",
    "    x = SimpleRNN(160, return_sequences=False, recurrent_dropout=0.2)(residual)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    output = Dense(2, activation='softmax')(x)\n",
    "    \n",
    "    \n",
    "    # create the model\n",
    "    model = Model(input_data, output)\n",
    "\n",
    "    # compile the model\n",
    "    optimizer = SGD(learning_rate=0.0019545050901889393)\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['precision', 'accuracy', 'recall'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# setup the data to be passed to the model\n",
    "X_train, y_train = timesteps_options_dict[6]['ROP']['X_train'], timesteps_options_dict[6]['ROP']['y_train']\n",
    "X_vald, y_vald = timesteps_options_dict[6]['ROP']['X_vald'], timesteps_options_dict[6]['ROP']['y_vald']\n",
    "X_test, y_test = timesteps_options_dict[6]['ROP']['X_test'], timesteps_options_dict[6]['ROP']['y_test']\n",
    "\n",
    "# initialize the model\n",
    "model1 = create_SimpleRNN_functional_residual(6, X_train.shape)\n",
    "\n",
    "# train the model\n",
    "history = model1.fit(X_train, y_train, validation_data=(X_vald, y_vald), epochs=50, batch_size=256, verbose=0)\n",
    "\n",
    "\n",
    "## Model evaluation and prototype conclusion\n",
    "\n",
    "# test the model accuracy\n",
    "model1.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# list the model architecture\n",
    "# model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "cde9a619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7214826941490173, 0.522292971611023, 0.522292971611023, 0.522292971611023]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the model accuracy\n",
    "model1.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "8d0a895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the model\n",
    "# plot_model(model1, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3fca0e",
   "metadata": {},
   "source": [
    "# Inception models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae5036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source of inspiration: The base Layer class, \"class ComputeSum(Layer)\", https://keras.io/2.15/api/layers/base_layer/\n",
    "# create a custom layer to split the features into groups (4 groups)\n",
    "class InputSpiltLayer(Layer):\n",
    "    def __init__(self, split_indices=[6, 10, 30, 36], **kwargs):\n",
    "        super(InputSpiltLayer, self).__init__(**kwargs)\n",
    "        \n",
    "        # set the split indices\n",
    "        self.split_indices = split_indices\n",
    "    \n",
    "    def call(self, inputs): # Defines the computation from inputs to outputs\n",
    "        \n",
    "        # initialize a list to store the input branches \n",
    "        data_set_branches = []\n",
    "    \n",
    "        # set the start index to be 0\n",
    "        start_index = 0\n",
    "\n",
    "        # iterates over the split_indices list\n",
    "        for i in self.split_indices:\n",
    "            \n",
    "            # take a slice of the data features that is between the start index and the ith value in the split_indices\n",
    "            branch = inputs[:, :, start_index:i]\n",
    "\n",
    "            # add the slice to the data_set_branches list\n",
    "            data_set_branches.append(branch)\n",
    "\n",
    "            # update the start_index to be equal to the ith value in the split_indices\n",
    "            start_index = i\n",
    "\n",
    "        # return the data_set_branches\n",
    "        return data_set_branches\n",
    "\n",
    "\n",
    "\n",
    "# def input_spilt(data_set, split_indices=[6, 10, 30, 36]):\n",
    "    \n",
    "#     data_set_branches = []\n",
    "    \n",
    "#     start_index = 0\n",
    "    \n",
    "#     for i in split_indices:\n",
    "#         branch = data_set[:, :, start_index:i]\n",
    "        \n",
    "#         data_set_branches.append(branch)\n",
    "        \n",
    "#         start_index = i\n",
    "        \n",
    "    \n",
    "#     return data_set_branches\n",
    "\n",
    "\n",
    "def create_model_branch(data_set_branch):\n",
    "#     input_data = Input(shape=(data_set_branch.shape[1], data_set_branch[2]))\n",
    "    \n",
    "    y = SeparableConv1D(filters=32, \n",
    "                              kernel_size=3, \n",
    "                              strides=1, \n",
    "                              padding='same', \n",
    "                              activation='relu')(data_set_branch)\n",
    "    y = BatchNormalization()(y)\n",
    "    # source: MaxPooling1D layer, https://keras.io/api/layers/pooling_layers/max_pooling1d/\n",
    "    # Max pooling operation for 1D temporal data. Downsamples the input representation by taking the maximum value over a spatial window of size pool_size. The window is shifted by strides.\n",
    "    y = MaxPooling1D()(y)\n",
    "    \n",
    "    x = SimpleRNN(256, return_sequences=True)(y)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = SimpleRNN(224, return_sequences=True, recurrent_dropout=0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = SimpleRNN(192, return_sequences=True, recurrent_dropout=0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = SimpleRNN(64, return_sequences=True, recurrent_dropout=0.4)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = SimpleRNN(224, return_sequences=True, recurrent_dropout=0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    y2 = SeparableConv1D(filters=32, \n",
    "                              kernel_size=3, \n",
    "                              strides=1, \n",
    "                              padding='same', \n",
    "                              activation='relu')(x)\n",
    "    y2 = BatchNormalization()(y2)\n",
    "    y2 = MaxPooling1D()(y2)\n",
    "    \n",
    "    residual = add([y, y2])\n",
    "\n",
    "    \n",
    "    x = SimpleRNN(160, return_sequences=False, recurrent_dropout=0.2)(residual)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "#     output = Dense(2, activation='softmax')(x)\n",
    "    \n",
    "    return x\n",
    "    \n",
    "    \n",
    "def create_SimpleRNN_inception_model(_timesteps, X_train_shape):\n",
    "    \n",
    "    # add the model layers\n",
    "    # input layer\n",
    "    input_data = Input(shape=(_timesteps, X_train_shape[2]))\n",
    "    \n",
    "    full_features_branch = create_model_branch(input_data)\n",
    "    \n",
    "    # source of inspiration: deep learning with python, 7.1.4. Directed acyclic graphs of layers, Inception modules, https://www.manning.com/books/deep-learning-with-python\n",
    "    data_set_branches = InputSpiltLayer([6, 10, 30, 36])(input_data)\n",
    "    \n",
    "    branch_1 = create_model_branch(data_set_branches[0])\n",
    "    branch_2 = create_model_branch(data_set_branches[1])\n",
    "    branch_3 = create_model_branch(data_set_branches[2])\n",
    "    branch_4 = create_model_branch(data_set_branches[3])\n",
    "    \n",
    "    \n",
    "    \n",
    "    branches_merged = concatenate([branch_1, branch_2, branch_3, branch_4, full_features_branch], axis=-1)    \n",
    "    \n",
    "    output = Dense(2, activation='softmax')(branches_merged)\n",
    "    \n",
    "    # create the model\n",
    "    model = Model(input_data, output)\n",
    "\n",
    "    # compile the model\n",
    "    optimizer = SGD(learning_rate=0.0019545050901889393)\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['precision', 'accuracy', 'recall'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# setup the data to be passed to the model\n",
    "X_train, y_train = timesteps_options_dict[6]['ROP']['X_train'], timesteps_options_dict[6]['ROP']['y_train']\n",
    "X_vald, y_vald = timesteps_options_dict[6]['ROP']['X_vald'], timesteps_options_dict[6]['ROP']['y_vald']\n",
    "X_test, y_test = timesteps_options_dict[6]['ROP']['X_test'], timesteps_options_dict[6]['ROP']['y_test']\n",
    "\n",
    "# initialize the model\n",
    "model1 = create_SimpleRNN_inception_model(6, X_train.shape)\n",
    "\n",
    "# train the model\n",
    "history = model1.fit(X_train, y_train, validation_data=(X_vald, y_vald), epochs=50, batch_size=256, verbose=0)\n",
    "\n",
    "\n",
    "## Model evaluation and prototype conclusion\n",
    "\n",
    "# test the model accuracy\n",
    "model1.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# list the model architecture\n",
    "# model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e70f130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the model\n",
    "plot_model(model1, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e84a457",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db293e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.evaluate(X_train, y_train, verbose=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
